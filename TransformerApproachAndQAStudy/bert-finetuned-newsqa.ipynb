{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7717e19a",
      "metadata": {
        "papermill": {
          "duration": 0.021339,
          "end_time": "2022-03-01T10:17:34.710059",
          "exception": false,
          "start_time": "2022-03-01T10:17:34.688720",
          "status": "completed"
        },
        "tags": [],
        "id": "7717e19a"
      },
      "source": [
        "# Finetune Bert on NewsQA\n",
        "**Student Credentials:** sdi1800119, Vissarion Moutafis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dbb86c8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-01T10:17:34.767478Z",
          "iopub.status.busy": "2022-03-01T10:17:34.757925Z",
          "iopub.status.idle": "2022-03-01T10:18:01.594232Z",
          "shell.execute_reply": "2022-03-01T10:18:01.593680Z",
          "shell.execute_reply.started": "2022-03-01T10:12:23.826839Z"
        },
        "papermill": {
          "duration": 26.864788,
          "end_time": "2022-03-01T10:18:01.594385",
          "exception": false,
          "start_time": "2022-03-01T10:17:34.729597",
          "status": "completed"
        },
        "tags": [],
        "id": "4dbb86c8",
        "outputId": "372fe948-994c-4d50-8177-37eadae8bbfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.15.0)\r\n",
            "Collecting datasets\r\n",
            "  Downloading datasets-1.18.3-py3-none-any.whl (311 kB)\r\n",
            "     |████████████████████████████████| 311 kB 5.0 MB/s            \r\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\r\n",
            "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.10.1)\r\n",
            "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.47)\r\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.4.2)\r\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.3)\r\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.2.1)\r\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.26.0)\r\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.20.3)\r\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\r\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\r\n",
            "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.62.3)\r\n",
            "Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.4)\r\n",
            "Collecting xxhash\r\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\r\n",
            "     |████████████████████████████████| 212 kB 53.1 MB/s            \r\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.1)\r\n",
            "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.12.2)\r\n",
            "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\r\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2022.1.0)\r\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (6.0.1)\r\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.0.1)\r\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.6)\r\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.0.9)\r\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.1)\r\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2021.10.8)\r\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.7)\r\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (5.2.0)\r\n",
            "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\r\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.1)\r\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.7.2)\r\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\r\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\r\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (21.2.0)\r\n",
            "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.6.0)\r\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\r\n",
            "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2021.3)\r\n",
            "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.1.0)\r\n",
            "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.3)\r\n",
            "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\r\n",
            "Installing collected packages: xxhash, datasets\r\n",
            "Successfully installed datasets-1.18.3 xxhash-3.0.0\r\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "The following NEW packages will be installed:\r\n",
            "  git-lfs\r\n",
            "0 upgraded, 1 newly installed, 0 to remove and 42 not upgraded.\r\n",
            "Need to get 3316 kB of archives.\r\n",
            "After this operation, 11.1 MB of additional disk space will be used.\r\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 git-lfs amd64 2.9.2-1 [3316 kB]\r\n",
            "Fetched 3316 kB in 1s (3484 kB/s)\r\n",
            "\n",
            "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package git-lfs.\r\n",
            "(Reading database ... 103272 files and directories currently installed.)\r\n",
            "Preparing to unpack .../git-lfs_2.9.2-1_amd64.deb ...\r\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 20%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Unpacking git-lfs (2.9.2-1) ...\r\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 40%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Setting up git-lfs (2.9.2-1) ...\r\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 60%]\u001b[49m\u001b[39m [##################################........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 80%]\u001b[49m\u001b[39m [##############################################............] \u001b8Processing triggers for man-db (2.9.1-1) ...\r\n",
            "\r\n",
            "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[JRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (4.62.3)\r\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn\n",
        "import re\n",
        "seaborn.set_style(\"ticks\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve, auc, classification_report\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchtext\n",
        "from torch.utils.data import SubsetRandomSampler\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "!pip install transformers datasets\n",
        "!apt install git-lfs\n",
        "import transformers\n",
        "import datasets\n",
        "from transformers import AutoModel, BertTokenizer, BertForSequenceClassification, AutoModelForSequenceClassification, AutoModelForQuestionAnswering\n",
        "from datasets import load_dataset, load_metric\n",
        "\n",
        "!pip install tqdm\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a88883a5",
      "metadata": {
        "papermill": {
          "duration": 0.032212,
          "end_time": "2022-03-01T10:18:01.659018",
          "exception": false,
          "start_time": "2022-03-01T10:18:01.626806",
          "status": "completed"
        },
        "tags": [],
        "id": "a88883a5"
      },
      "source": [
        "## Load the model and dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ac97302",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-01T10:18:01.728526Z",
          "iopub.status.busy": "2022-03-01T10:18:01.727786Z",
          "iopub.status.idle": "2022-03-01T10:18:01.729809Z",
          "shell.execute_reply": "2022-03-01T10:18:01.730241Z",
          "shell.execute_reply.started": "2022-03-01T10:12:50.716570Z"
        },
        "papermill": {
          "duration": 0.038988,
          "end_time": "2022-03-01T10:18:01.730374",
          "exception": false,
          "start_time": "2022-03-01T10:18:01.691386",
          "status": "completed"
        },
        "tags": [],
        "id": "6ac97302"
      },
      "outputs": [],
      "source": [
        "model_checkpoint = 'bert-base-uncased'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd1af3af",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-01T10:18:01.799951Z",
          "iopub.status.busy": "2022-03-01T10:18:01.799440Z",
          "iopub.status.idle": "2022-03-01T10:18:18.175811Z",
          "shell.execute_reply": "2022-03-01T10:18:18.176224Z",
          "shell.execute_reply.started": "2022-03-01T10:12:50.722822Z"
        },
        "papermill": {
          "duration": 16.414723,
          "end_time": "2022-03-01T10:18:18.176373",
          "exception": false,
          "start_time": "2022-03-01T10:18:01.761650",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "3599c261ed10496eb81d376b91197428",
            "69f64532d4cd40bfb9078b71d7909da0"
          ]
        },
        "id": "dd1af3af",
        "outputId": "783e4399-6429-47c3-c2b2-4f1b4bc47e54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset squad_like/default to /root/.cache/huggingface/datasets/squad_like/default-7708c4ccd509e0f9/0.0.0/c11bde73ef00f53b085b6a086d13514938f65b80af061fc874ce3e7514c24892...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3599c261ed10496eb81d376b91197428",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69f64532d4cd40bfb9078b71d7909da0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset squad_like downloaded and prepared to /root/.cache/huggingface/datasets/squad_like/default-7708c4ccd509e0f9/0.0.0/c11bde73ef00f53b085b6a086d13514938f65b80af061fc874ce3e7514c24892. Subsequent calls will reuse this data.\n"
          ]
        }
      ],
      "source": [
        "train_dataset = load_dataset('../input/squadlikeloader/squad_like.py', data_files={'train':'../newsqatosquad/newsqa-train.csv', 'validation':'../newsqatosquad/newsqa-dev.csv'}, split='train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79ae2685",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-01T10:18:18.251142Z",
          "iopub.status.busy": "2022-03-01T10:18:18.249709Z",
          "iopub.status.idle": "2022-03-01T10:18:34.022472Z",
          "shell.execute_reply": "2022-03-01T10:18:34.021931Z",
          "shell.execute_reply.started": "2022-03-01T10:13:08.266731Z"
        },
        "papermill": {
          "duration": 15.811259,
          "end_time": "2022-03-01T10:18:34.022633",
          "exception": false,
          "start_time": "2022-03-01T10:18:18.211374",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "27af2ad150e54ae89d101115024e1ffd",
            "2d10813d85504c84aad3479db578527d",
            "82ab58e473a04a1ca8c09065547c15c2",
            "f6561fefded24fe8ae331d8303e18546",
            "7755f89b17a1458c86e5250514d4feef",
            "09443e7e85d64f6a882b5bb48e3fb3ec",
            "8fdab88dfe2b4509b8a9f8623a71bac3",
            "738574a5b4244cb79d7c5a8c605c8b5b"
          ]
        },
        "id": "79ae2685",
        "outputId": "428f538e-e536-4188-8f4d-992b826d2553"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "27af2ad150e54ae89d101115024e1ffd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.87k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d10813d85504c84aad3479db578527d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset squad_v2/squad_v2 (download: 44.34 MiB, generated: 122.41 MiB, post-processed: Unknown size, total: 166.75 MiB) to /root/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82ab58e473a04a1ca8c09065547c15c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6561fefded24fe8ae331d8303e18546",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/9.55M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7755f89b17a1458c86e5250514d4feef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/801k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09443e7e85d64f6a882b5bb48e3fb3ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8fdab88dfe2b4509b8a9f8623a71bac3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "738574a5b4244cb79d7c5a8c605c8b5b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset squad_v2 downloaded and prepared to /root/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d. Subsequent calls will reuse this data.\n"
          ]
        }
      ],
      "source": [
        "test_dataset = load_dataset('squad_v2', split='validation')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess dataset"
      ],
      "metadata": {
        "id": "h7kCLcfnGMnq"
      },
      "id": "h7kCLcfnGMnq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3177c02b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-01T10:18:34.106075Z",
          "iopub.status.busy": "2022-03-01T10:18:34.105376Z",
          "iopub.status.idle": "2022-03-01T10:18:36.052025Z",
          "shell.execute_reply": "2022-03-01T10:18:36.052675Z",
          "shell.execute_reply.started": "2022-03-01T09:57:52.103920Z"
        },
        "papermill": {
          "duration": 1.989039,
          "end_time": "2022-03-01T10:18:36.052853",
          "exception": false,
          "start_time": "2022-03-01T10:18:34.063814",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "b7fb8360821248e6a316b7e2371f9e59",
            "d0da8d6884be49b686cf47d94e274b78",
            "dcc0ffa798ab45d4bc3d15e77dd6c012",
            "3a45cd4f1e6d438eb3c2d48c0cbb0b57"
          ]
        },
        "id": "3177c02b",
        "outputId": "45163be7-a3d1-4c7e-9b43-f4eddd6d154c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7fb8360821248e6a316b7e2371f9e59",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0da8d6884be49b686cf47d94e274b78",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dcc0ffa798ab45d4bc3d15e77dd6c012",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a45cd4f1e6d438eb3c2d48c0cbb0b57",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "# initialize the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "MAX_LENGTH = 384\n",
        "DOC_STRIDE = 128 # multi-context overlapping range for large context'd instances \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3592217f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-01T10:18:36.191683Z",
          "iopub.status.busy": "2022-03-01T10:18:36.190778Z",
          "iopub.status.idle": "2022-03-01T10:18:36.192650Z",
          "shell.execute_reply": "2022-03-01T10:18:36.193331Z",
          "shell.execute_reply.started": "2022-03-01T09:57:59.630710Z"
        },
        "papermill": {
          "duration": 0.073574,
          "end_time": "2022-03-01T10:18:36.193503",
          "exception": false,
          "start_time": "2022-03-01T10:18:36.119929",
          "status": "completed"
        },
        "tags": [],
        "id": "3592217f"
      },
      "outputs": [],
      "source": [
        "def preprocess_squad(examples):\n",
        "  # get the questions and the context\n",
        "  questions = [q.strip() for q in examples[\"question\"]]\n",
        "  context = examples[\"context\"]\n",
        "  # tokenize questions along with the context \n",
        "  inputs = tokenizer(\n",
        "        questions,\n",
        "        context,\n",
        "        max_length=MAX_LENGTH,\n",
        "        stride=DOC_STRIDE,\n",
        "        truncation=\"only_second\",\n",
        "        padding=\"max_length\",\n",
        "        return_offsets_mapping=True,\n",
        "        return_overflowing_tokens=True\n",
        "    )\n",
        "  offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "  sample_mapping = inputs.pop(\"overflow_to_sample_mapping\")\n",
        "  answers = examples[\"answers\"]\n",
        "  start_positions = []\n",
        "  end_positions = []\n",
        "  \n",
        "  for i, offset in enumerate(offset_mapping):\n",
        "    sample_index = sample_mapping[i]\n",
        "    answer = examples[\"answers\"][sample_index]\n",
        "    # if there is no answer default to [CLS]\n",
        "    if not answer[\"answer_start\"]:\n",
        "      start_positions.append(inputs['input_ids'][i].index(tokenizer.cls_token_id))\n",
        "      end_positions.append(inputs['input_ids'][i].index(tokenizer.cls_token_id))\n",
        "      continue \n",
        "    \n",
        "    # get answer start and end positions\n",
        "    start_char = answer[\"answer_start\"][0]\n",
        "    end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
        "    sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "    # Find the start and end of the context\n",
        "    idx = 0\n",
        "    while sequence_ids[idx] != 1:\n",
        "      idx += 1\n",
        "    context_start = idx\n",
        "    while sequence_ids[idx] == 1:\n",
        "      idx += 1\n",
        "    context_end = idx - 1\n",
        "\n",
        "    # If the answer is not fully inside the context, label it (0, 0)\n",
        "    if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
        "#       start_positions.append(inputs['input_ids'][i].index(tokenizer.cls_token_id))\n",
        "#       end_positions.append(inputs['input_ids'][i].index(tokenizer.cls_token_id))\n",
        "      start_positions.append(-1)\n",
        "      end_positions.append(-1)\n",
        "    else:\n",
        "      # Otherwise it's the start and end token positions\n",
        "      idx = context_start\n",
        "      while idx <= context_end and offset[idx][0] <= start_char:\n",
        "        idx += 1\n",
        "      start_positions.append(idx - 1)\n",
        "\n",
        "      idx = context_end\n",
        "      while idx >= context_start and offset[idx][1] >= end_char:\n",
        "        idx -= 1\n",
        "      end_positions.append(idx + 1)\n",
        "\n",
        "  inputs[\"start_positions\"] = start_positions\n",
        "  inputs[\"end_positions\"] = end_positions\n",
        "  return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f55c9eb5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-01T10:18:36.286359Z",
          "iopub.status.busy": "2022-03-01T10:18:36.285493Z",
          "iopub.status.idle": "2022-03-01T10:18:46.721069Z",
          "shell.execute_reply": "2022-03-01T10:18:46.720640Z",
          "shell.execute_reply.started": "2022-03-01T09:57:59.651801Z"
        },
        "papermill": {
          "duration": 10.488026,
          "end_time": "2022-03-01T10:18:46.721194",
          "exception": false,
          "start_time": "2022-03-01T10:18:36.233168",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "feb758ff2ec74494b22e4420fe20b3c5",
            "20414fd8420d48c799917f606184126e"
          ]
        },
        "id": "f55c9eb5",
        "outputId": "e3dc07f7-a2fe-46bd-d33c-1dbd058c06db"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "feb758ff2ec74494b22e4420fe20b3c5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/93 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20414fd8420d48c799917f606184126e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/12 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def appropriate_length(q, c):\n",
        "#     if len(q) + 3 >= DOC_STRIDE:\n",
        "#         print(q)\n",
        "    tq = tokenizer(q)['input_ids']\n",
        "    return len(tq) <= DOC_STRIDE\n",
        "\n",
        "train_dataset = train_dataset.filter(appropriate_length, input_columns=['question', 'context'])\n",
        "test_dataset = test_dataset.filter(appropriate_length, input_columns=['question', 'context'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27dcf27d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-01T10:18:46.824942Z",
          "iopub.status.busy": "2022-03-01T10:18:46.820009Z",
          "iopub.status.idle": "2022-03-01T10:24:52.852053Z",
          "shell.execute_reply": "2022-03-01T10:24:52.852841Z",
          "shell.execute_reply.started": "2022-03-01T09:58:13.786988Z"
        },
        "papermill": {
          "duration": 366.089318,
          "end_time": "2022-03-01T10:24:52.853026",
          "exception": false,
          "start_time": "2022-03-01T10:18:46.763708",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "63b5154d919c452e95bddf104bf04d69",
            "5446ba9be7d44b77a034a1e2d8667f2e"
          ]
        },
        "id": "27dcf27d",
        "outputId": "16de40d2-3176-4905-c68e-2be17fb21464"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63b5154d919c452e95bddf104bf04d69",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/93 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5446ba9be7d44b77a034a1e2d8667f2e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/12 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_dataset = train_dataset.map(preprocess_squad, batched=True, remove_columns=train_dataset.column_names)\n",
        "test_dataset = test_dataset.map(preprocess_squad, batched=True, remove_columns=test_dataset.column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff496cc2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-01T10:24:52.964235Z",
          "iopub.status.busy": "2022-03-01T10:24:52.963348Z",
          "iopub.status.idle": "2022-03-01T10:24:53.747178Z",
          "shell.execute_reply": "2022-03-01T10:24:53.746757Z",
          "shell.execute_reply.started": "2022-03-01T10:04:59.602723Z"
        },
        "papermill": {
          "duration": 0.85221,
          "end_time": "2022-03-01T10:24:53.747302",
          "exception": false,
          "start_time": "2022-03-01T10:24:52.895092",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "17d7bf0398ec4a96b3f11590c4ab8e79",
            "15a88b46324f42a4a623bab52e9c7ad1"
          ]
        },
        "id": "ff496cc2",
        "outputId": "d067feb1-eebc-4f89-ea55-238161dfa6ba"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17d7bf0398ec4a96b3f11590c4ab8e79",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/310 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15a88b46324f42a4a623bab52e9c7ad1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/13 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def is_valid(s, e):\n",
        "    return s != -1 and e != -1\n",
        "\n",
        "train_dataset = train_dataset.filter(is_valid, input_columns=['start_positions', 'end_positions'])\n",
        "test_dataset = test_dataset.filter(is_valid, input_columns=['start_positions', 'end_positions'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e86d8ca0",
      "metadata": {
        "papermill": {
          "duration": 0.04188,
          "end_time": "2022-03-01T10:24:53.831728",
          "exception": false,
          "start_time": "2022-03-01T10:24:53.789848",
          "status": "completed"
        },
        "tags": [],
        "id": "e86d8ca0"
      },
      "source": [
        "## Fine Tunning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f35d5335",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-01T10:24:53.922342Z",
          "iopub.status.busy": "2022-03-01T10:24:53.921538Z",
          "iopub.status.idle": "2022-03-01T10:24:53.923332Z",
          "shell.execute_reply": "2022-03-01T10:24:53.923808Z",
          "shell.execute_reply.started": "2022-03-01T10:06:23.799667Z"
        },
        "papermill": {
          "duration": 0.049185,
          "end_time": "2022-03-01T10:24:53.923952",
          "exception": false,
          "start_time": "2022-03-01T10:24:53.874767",
          "status": "completed"
        },
        "tags": [],
        "id": "f35d5335"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=24, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=24, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4318b1a0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-01T10:24:54.017118Z",
          "iopub.status.busy": "2022-03-01T10:24:54.016595Z",
          "iopub.status.idle": "2022-03-01T10:25:05.650979Z",
          "shell.execute_reply": "2022-03-01T10:25:05.650552Z",
          "shell.execute_reply.started": "2022-03-01T10:15:30.146768Z"
        },
        "papermill": {
          "duration": 11.684466,
          "end_time": "2022-03-01T10:25:05.651101",
          "exception": false,
          "start_time": "2022-03-01T10:24:53.966635",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "94f6c294d82f4b4685559dc620199bf1"
          ]
        },
        "id": "4318b1a0",
        "outputId": "81fbd225-9ea5-412f-a663-3e11ff4921e1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94f6c294d82f4b4685559dc620199bf1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd98c60c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-01T10:25:05.744638Z",
          "iopub.status.busy": "2022-03-01T10:25:05.744094Z",
          "iopub.status.idle": "2022-03-01T10:25:08.794049Z",
          "shell.execute_reply": "2022-03-01T10:25:08.794644Z",
          "shell.execute_reply.started": "2022-03-01T10:06:43.115968Z"
        },
        "papermill": {
          "duration": 3.100152,
          "end_time": "2022-03-01T10:25:08.794812",
          "exception": false,
          "start_time": "2022-03-01T10:25:05.694660",
          "status": "completed"
        },
        "tags": [],
        "id": "bd98c60c",
        "outputId": "5ffe7fa8-9276-4fbf-c5be-976158f402c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertForQuestionAnswering(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "model.to(device)\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aea9f8e2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-01T10:25:08.907816Z",
          "iopub.status.busy": "2022-03-01T10:25:08.906861Z",
          "iopub.status.idle": "2022-03-01T10:25:08.917357Z",
          "shell.execute_reply": "2022-03-01T10:25:08.917805Z",
          "shell.execute_reply.started": "2022-03-01T10:06:46.568195Z"
        },
        "papermill": {
          "duration": 0.073709,
          "end_time": "2022-03-01T10:25:08.917963",
          "exception": false,
          "start_time": "2022-03-01T10:25:08.844254",
          "status": "completed"
        },
        "tags": [],
        "id": "aea9f8e2"
      },
      "outputs": [],
      "source": [
        "def training_step(model, optimizer, epoch_i, train_loader, history=None):\n",
        "  torch.cuda.empty_cache()\n",
        "  # 1 step of backprop with train/test error estimation\n",
        "  total_loss = 0\n",
        "  acc = []\n",
        "  pbar = tqdm(train_loader)\n",
        "  for i,batch in enumerate(pbar):\n",
        "    torch.cuda.empty_cache()\n",
        "    # set the gradients to zero for new estimation\n",
        "    optimizer.zero_grad() \n",
        "    # forward pass\n",
        "    args = {\n",
        "        \"start_positions\" : torch.LongTensor(batch[\"start_positions\"]).to(device),\n",
        "        \"end_positions\" : torch.LongTensor(batch[\"end_positions\"]).to(device),\n",
        "        \"input_ids\" : torch.stack(batch[\"input_ids\"], axis=1).to(device),\n",
        "        \"attention_mask\" : torch.stack(batch[\"attention_mask\"], axis=1).to(device),\n",
        "    }\n",
        "    outputs = model(**args) \n",
        "    loss = outputs[0]\n",
        "    start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
        "    end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
        "    # compute loss \n",
        "    total_loss += loss.item()\n",
        "\n",
        "    # backpropagate error\n",
        "    loss.backward()\n",
        "    # apply gradient clipping adjust model's parameters\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
        "    optimizer.step()\n",
        "    \n",
        "    acc.append(((start_pred == args['start_positions']).sum()/len(start_pred)).item())\n",
        "    acc.append(((end_pred == args['end_positions']).sum()/len(end_pred)).item())\n",
        "    pbar.set_description('Epoch {}: train loss: {}, train accuracy: {}%'.format(epoch_i, total_loss/(i+1), sum(acc)/len(acc)), refresh=True)\n",
        "    \n",
        "  train_loss = total_loss/len(train_loader)\n",
        "    \n",
        "    # if the user provides with a history dict the training step will save the current epoch's train-test loss\n",
        "  if history is not None: \n",
        "    history['train'].append(train_loss)\n",
        "  \n",
        "  test_loss = 0\n",
        "  acc = []\n",
        "  pbar = tqdm(test_loader)\n",
        "  for i,batch in enumerate(pbar):\n",
        "    torch.cuda.empty_cache()\n",
        "    with torch.no_grad():\n",
        "      args = {\n",
        "          \"start_positions\" : torch.LongTensor(batch[\"start_positions\"]).to(device),\n",
        "          \"end_positions\" : torch.LongTensor(batch[\"end_positions\"]).to(device),\n",
        "          \"input_ids\" : torch.stack(batch[\"input_ids\"], axis=1).to(device),\n",
        "          \"attention_mask\" : torch.stack(batch[\"attention_mask\"], axis=1).to(device)\n",
        "        }\n",
        "      outputs = model(**args)\n",
        "      test_loss += outputs[0].item()\n",
        "      start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
        "      end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
        "      acc.append(((start_pred == args['start_positions']).sum()/len(start_pred)).item())\n",
        "      acc.append(((end_pred == args['end_positions']).sum()/len(end_pred)).item())\n",
        "      pbar.set_description('Epoch {}: test loss {}%, test accuracy {}%'.format(epoch_i, test_loss/(i+1), sum(acc)/len(acc)), refresh=True)\n",
        "        \n",
        "  if history is not None: \n",
        "    history['test'].append(test_loss/len(test_loader))\n",
        "    \n",
        "\n",
        "  \n",
        "  return train_loss, test_loss/len(test_loader), sum(acc)/len(acc)\n",
        "\n",
        "def train_model(history, model, train_loader, epochs, _lr):\n",
        "  # set to training mode\n",
        "  model.train()\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.AdamW(model.parameters(), lr = _lr)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    training_step(model, optimizer, epoch, train_loader, history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f08b6f7b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-01T10:25:09.022127Z",
          "iopub.status.busy": "2022-03-01T10:25:09.021372Z",
          "iopub.status.idle": "2022-03-01T13:53:11.607011Z",
          "shell.execute_reply": "2022-03-01T13:53:11.570738Z",
          "shell.execute_reply.started": "2022-03-01T10:06:46.603029Z"
        },
        "papermill": {
          "duration": 12482.640439,
          "end_time": "2022-03-01T13:53:11.607142",
          "exception": false,
          "start_time": "2022-03-01T10:25:08.966703",
          "status": "completed"
        },
        "tags": [],
        "id": "f08b6f7b",
        "outputId": "ec5e4373-f10e-43fa-bd7e-a15c196eebc9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 0: train loss: 2.1081521216140895, train accuracy: 0.4782033378425239%: 100%|██████████| 4442/4442 [1:40:49<00:00,  1.36s/it]\n",
            "Epoch 0: test loss 5.961829203058524%, test accuracy 0.26363989292640255%: 100%|██████████| 502/502 [03:04<00:00,  2.73it/s]\n",
            "Epoch 1: train loss: 1.4056846524065865, train accuracy: 0.620049170056129%: 100%|██████████| 4442/4442 [1:41:01<00:00,  1.36s/it]\n",
            "Epoch 1: test loss 6.863680784445835%, test accuracy 0.26007083554073157%: 100%|██████████| 502/502 [03:04<00:00,  2.72it/s]\n"
          ]
        }
      ],
      "source": [
        "history = {'train':[], 'test':[]}\n",
        "train_model(history, model, train_loader, 2,  3e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a9ca94a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-01T13:53:24.328298Z",
          "iopub.status.busy": "2022-03-01T13:53:24.327518Z",
          "iopub.status.idle": "2022-03-01T13:53:25.789453Z",
          "shell.execute_reply": "2022-03-01T13:53:25.789935Z"
        },
        "papermill": {
          "duration": 7.857918,
          "end_time": "2022-03-01T13:53:25.790102",
          "exception": false,
          "start_time": "2022-03-01T13:53:17.932184",
          "status": "completed"
        },
        "tags": [],
        "id": "8a9ca94a",
        "outputId": "217d6df7-8faf-4c37-9e48-3b07632060b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        }
      ],
      "source": [
        "!mkdir bert-finetuned-newsqa\n",
        "model.save_pretrained('./bert-finetuned-newsqa/' , private=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78947ddd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-01T13:53:38.912131Z",
          "iopub.status.busy": "2022-03-01T13:53:38.911211Z",
          "iopub.status.idle": "2022-03-01T13:54:52.497416Z",
          "shell.execute_reply": "2022-03-01T13:54:52.497822Z",
          "shell.execute_reply.started": "2022-03-01T10:15:43.363712Z"
        },
        "papermill": {
          "duration": 80.640029,
          "end_time": "2022-03-01T13:54:52.497975",
          "exception": false,
          "start_time": "2022-03-01T13:53:31.857946",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "7168b09c2cfd4047aba1049646eeff9c"
          ]
        },
        "id": "78947ddd",
        "outputId": "f3d2597c-1e61-40fc-cbd0-d0545f1530c2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/huggingface_hub/hf_api.py:726: FutureWarning: `create_repo` now takes `token` as an optional positional argument. Be sure to adapt your code!\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cloning https://huggingface.co/vissa/bert-finetuned-newsqa into local empty directory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7168b09c2cfd4047aba1049646eeff9c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload file pytorch_model.bin:   0%|          | 32.0k/415M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "To https://huggingface.co/vissa/bert-finetuned-newsqa\n",
            "   d3f3f0c..5b65025  main -> main\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'https://huggingface.co/vissa/bert-finetuned-newsqa/commit/5b650254c812f223e12cd447fa2ab4f7148d6b37'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.push_to_hub('vissa/bert-finetuned-newsqa', use_auth_token='YOUR_WRT_TOKKEN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24026fe6",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-28T11:58:50.853201Z",
          "iopub.status.idle": "2022-02-28T11:58:50.854769Z",
          "shell.execute_reply": "2022-02-28T11:58:50.854519Z",
          "shell.execute_reply.started": "2022-02-28T11:58:50.854456Z"
        },
        "papermill": {
          "duration": 6.513795,
          "end_time": "2022-03-01T13:55:05.147496",
          "exception": false,
          "start_time": "2022-03-01T13:54:58.633701",
          "status": "completed"
        },
        "tags": [],
        "id": "24026fe6"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99ac3b8a",
      "metadata": {
        "papermill": {
          "duration": 6.528262,
          "end_time": "2022-03-01T13:55:18.282570",
          "exception": false,
          "start_time": "2022-03-01T13:55:11.754308",
          "status": "completed"
        },
        "tags": [],
        "id": "99ac3b8a"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 13080.875468,
      "end_time": "2022-03-01T13:55:27.314981",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-03-01T10:17:26.439513",
      "version": "2.3.3"
    },
    "colab": {
      "name": "bert-finetuned-newsqa.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}