{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Final Evaluation\n",
        "\n",
        "**Student Credentials:** sdi1800119, Vissarion Moutafis\n",
        "\n",
        "In this notebook we will use the trained models, saved in hugging-face hub and the datasets, stored in kaggle-datasets repos, in our attempt to replicate the results of the given paper. The results are quite interesting.\n",
        "\n",
        "We will use the same preprocessing as in training process and remove all samples where the question is larger than the doc stride."
      ],
      "metadata": {
        "id": "IGPXLhMZq6Il"
      },
      "id": "IGPXLhMZq6Il"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5c04504",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2022-03-12T14:07:41.558394Z",
          "iopub.status.busy": "2022-03-12T14:07:41.556893Z",
          "iopub.status.idle": "2022-03-12T14:08:09.164518Z",
          "shell.execute_reply": "2022-03-12T14:08:09.163969Z",
          "shell.execute_reply.started": "2022-03-03T20:37:31.996159Z"
        },
        "papermill": {
          "duration": 27.627561,
          "end_time": "2022-03-12T14:08:09.164659",
          "exception": false,
          "start_time": "2022-03-12T14:07:41.537098",
          "status": "completed"
        },
        "tags": [],
        "id": "c5c04504",
        "outputId": "c6bc9c7e-b22a-46b9-a9c6-a04839b9b989"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.15.0)\r\n",
            "Collecting datasets\r\n",
            "  Downloading datasets-1.18.4-py3-none-any.whl (312 kB)\r\n",
            "     |████████████████████████████████| 312 kB 779 kB/s            \r\n",
            "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.26.0)\r\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\r\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.20.3)\r\n",
            "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.10.1)\r\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.4.2)\r\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\r\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.2.1)\r\n",
            "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.62.3)\r\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.3)\r\n",
            "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.47)\r\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\r\n",
            "Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.4)\r\n",
            "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.12.2)\r\n",
            "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\r\n",
            "Collecting xxhash\r\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\r\n",
            "     |████████████████████████████████| 212 kB 10.3 MB/s            \r\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2022.1.0)\r\n",
            "Collecting responses<0.19\r\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\r\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (6.0.1)\r\n",
            "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.1)\r\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.0.1)\r\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.6)\r\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.0.9)\r\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2021.10.8)\r\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.1)\r\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.7)\r\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.7.2)\r\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\r\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.1)\r\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (5.2.0)\r\n",
            "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\r\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\r\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (21.2.0)\r\n",
            "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.6.0)\r\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\r\n",
            "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2021.3)\r\n",
            "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\r\n",
            "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.3)\r\n",
            "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.1.0)\r\n",
            "Installing collected packages: xxhash, responses, datasets\r\n",
            "Successfully installed datasets-1.18.4 responses-0.18.0 xxhash-3.0.0\r\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "The following NEW packages will be installed:\r\n",
            "  git-lfs\r\n",
            "0 upgraded, 1 newly installed, 0 to remove and 42 not upgraded.\r\n",
            "Need to get 3316 kB of archives.\r\n",
            "After this operation, 11.1 MB of additional disk space will be used.\r\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 git-lfs amd64 2.9.2-1 [3316 kB]\r\n",
            "Fetched 3316 kB in 2s (2155 kB/s)\r\n",
            "\n",
            "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package git-lfs.\r\n",
            "(Reading database ... 103272 files and directories currently installed.)\r\n",
            "Preparing to unpack .../git-lfs_2.9.2-1_amd64.deb ...\r\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 20%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Unpacking git-lfs (2.9.2-1) ...\r\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 40%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Setting up git-lfs (2.9.2-1) ...\r\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 60%]\u001b[49m\u001b[39m [##################################........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 80%]\u001b[49m\u001b[39m [##############################################............] \u001b8Processing triggers for man-db (2.9.1-1) ...\r\n",
            "\r\n",
            "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[JRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (4.62.3)\r\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn\n",
        "import re\n",
        "seaborn.set_style(\"ticks\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve, auc, classification_report\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchtext\n",
        "from torch.utils.data import SubsetRandomSampler\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "!pip install transformers datasets\n",
        "!apt install git-lfs\n",
        "import transformers\n",
        "import datasets\n",
        "from transformers import AutoModel, BertTokenizer, BertForSequenceClassification, AutoModelForSequenceClassification, AutoModelForQuestionAnswering\n",
        "from datasets import load_dataset, load_metric\n",
        "\n",
        "!pip install tqdm\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Datasets"
      ],
      "metadata": {
        "id": "TsXFcuwjHIZ0"
      },
      "id": "TsXFcuwjHIZ0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c56767a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-12T14:08:09.235390Z",
          "iopub.status.busy": "2022-03-12T14:08:09.234668Z",
          "iopub.status.idle": "2022-03-12T14:08:09.236808Z",
          "shell.execute_reply": "2022-03-12T14:08:09.237305Z",
          "shell.execute_reply.started": "2022-03-03T20:37:58.216126Z"
        },
        "papermill": {
          "duration": 0.03965,
          "end_time": "2022-03-12T14:08:09.237429",
          "exception": false,
          "start_time": "2022-03-12T14:08:09.197779",
          "status": "completed"
        },
        "tags": [],
        "id": "9c56767a"
      },
      "outputs": [],
      "source": [
        "token='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'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d12f011d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-12T14:08:09.309576Z",
          "iopub.status.busy": "2022-03-12T14:08:09.308639Z",
          "iopub.status.idle": "2022-03-12T14:08:24.728996Z",
          "shell.execute_reply": "2022-03-12T14:08:24.729586Z",
          "shell.execute_reply.started": "2022-03-03T21:08:38.928219Z"
        },
        "papermill": {
          "duration": 15.460858,
          "end_time": "2022-03-12T14:08:24.729778",
          "exception": false,
          "start_time": "2022-03-12T14:08:09.268920",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "f5c96fcf063f487fa2b7e2a5f7f11653",
            "a18470fdd9884622b3be32706ed0bd0f",
            "76d909a4f9b04385ad01a2a30bf5273f",
            "c0df7fc36f164d86a61975a761107cb1",
            "7dfa9acfc1c54925b1d570a3bdef3197",
            "0785e5e7e56d49e2aaa7495b772c04d5",
            "7b175f9e6bc84537aecd66cddfc67f37",
            "9a54f3539815477d9b47773b7d3b11e2"
          ]
        },
        "id": "d12f011d",
        "outputId": "84e66c15-b99c-438f-a677-07e68e11943d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5c96fcf063f487fa2b7e2a5f7f11653",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.87k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a18470fdd9884622b3be32706ed0bd0f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset squad_v2/squad_v2 (download: 44.34 MiB, generated: 122.41 MiB, post-processed: Unknown size, total: 166.75 MiB) to /root/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76d909a4f9b04385ad01a2a30bf5273f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0df7fc36f164d86a61975a761107cb1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/9.55M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7dfa9acfc1c54925b1d570a3bdef3197",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/801k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0785e5e7e56d49e2aaa7495b772c04d5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b175f9e6bc84537aecd66cddfc67f37",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a54f3539815477d9b47773b7d3b11e2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset squad_v2 downloaded and prepared to /root/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d. Subsequent calls will reuse this data.\n"
          ]
        }
      ],
      "source": [
        "squad_dt = load_dataset('squad_v2', split='validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "228d47d0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-12T14:08:24.810765Z",
          "iopub.status.busy": "2022-03-12T14:08:24.810239Z",
          "iopub.status.idle": "2022-03-12T14:08:31.335087Z",
          "shell.execute_reply": "2022-03-12T14:08:31.335699Z",
          "shell.execute_reply.started": "2022-03-03T21:08:39.330097Z"
        },
        "papermill": {
          "duration": 6.566533,
          "end_time": "2022-03-12T14:08:31.335895",
          "exception": false,
          "start_time": "2022-03-12T14:08:24.769362",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "1c7e6763f4974cafb0e5ff486154b1c3",
            "e2de634aaf1f44c792a2b83477880ea6"
          ]
        },
        "id": "228d47d0",
        "outputId": "918a475c-d4a1-482c-f474-2ef2bd0a4958"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset squad_like/default to /root/.cache/huggingface/datasets/squad_like/default-7731d89230024ff0/0.0.0/c11bde73ef00f53b085b6a086d13514938f65b80af061fc874ce3e7514c24892...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c7e6763f4974cafb0e5ff486154b1c3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2de634aaf1f44c792a2b83477880ea6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset squad_like downloaded and prepared to /root/.cache/huggingface/datasets/squad_like/default-7731d89230024ff0/0.0.0/c11bde73ef00f53b085b6a086d13514938f65b80af061fc874ce3e7514c24892. Subsequent calls will reuse this data.\n"
          ]
        }
      ],
      "source": [
        "triviaqa_dt = load_dataset('../input/squadlikeloader/squad_like.py', data_files={'validation':'../triviaqatosquad/triviaqa_dev.json', 'train':'../triviaqatosquad/triviaqa_dev.json'}, split='validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30c3fa14",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-12T14:08:31.416677Z",
          "iopub.status.busy": "2022-03-12T14:08:31.415900Z",
          "iopub.status.idle": "2022-03-12T14:08:32.456969Z",
          "shell.execute_reply": "2022-03-12T14:08:32.457529Z",
          "shell.execute_reply.started": "2022-03-03T21:08:39.355855Z"
        },
        "papermill": {
          "duration": 1.082867,
          "end_time": "2022-03-12T14:08:32.457725",
          "exception": false,
          "start_time": "2022-03-12T14:08:31.374858",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "9eb68e4f568a40fcb723d3f2582d553a",
            "64948f20c880480987461b749cb4c9df"
          ]
        },
        "id": "30c3fa14",
        "outputId": "790c62f3-39a8-4aaf-d360-00a139b76444"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset squad_like/default to /root/.cache/huggingface/datasets/squad_like/default-c80748befeddccb3/0.0.0/c11bde73ef00f53b085b6a086d13514938f65b80af061fc874ce3e7514c24892...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9eb68e4f568a40fcb723d3f2582d553a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64948f20c880480987461b749cb4c9df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset squad_like downloaded and prepared to /root/.cache/huggingface/datasets/squad_like/default-c80748befeddccb3/0.0.0/c11bde73ef00f53b085b6a086d13514938f65b80af061fc874ce3e7514c24892. Subsequent calls will reuse this data.\n"
          ]
        }
      ],
      "source": [
        "nq_dt= load_dataset('../input/squadlikeloader/squad_like.py', data_files={'validation':'../nqtosquad/nq_dev.json', 'train':'../nqtosquad/nq_dev.json'}, split='validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b9a5b25",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-12T14:08:32.540736Z",
          "iopub.status.busy": "2022-03-12T14:08:32.540031Z",
          "iopub.status.idle": "2022-03-12T14:08:34.296819Z",
          "shell.execute_reply": "2022-03-12T14:08:34.297299Z",
          "shell.execute_reply.started": "2022-03-03T21:08:39.377931Z"
        },
        "papermill": {
          "duration": 1.799554,
          "end_time": "2022-03-12T14:08:34.297451",
          "exception": false,
          "start_time": "2022-03-12T14:08:32.497897",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "0ddfc881088147bbbf3e83fad4db55b0",
            "6a00acb96e15470d8f7d7416e1ea14a1"
          ]
        },
        "id": "3b9a5b25",
        "outputId": "4d062437-6990-4d3e-ef35-ba9ab27741bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset squad_like/default to /root/.cache/huggingface/datasets/squad_like/default-6f35545f73d12f1c/0.0.0/c11bde73ef00f53b085b6a086d13514938f65b80af061fc874ce3e7514c24892...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ddfc881088147bbbf3e83fad4db55b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a00acb96e15470d8f7d7416e1ea14a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset squad_like downloaded and prepared to /root/.cache/huggingface/datasets/squad_like/default-6f35545f73d12f1c/0.0.0/c11bde73ef00f53b085b6a086d13514938f65b80af061fc874ce3e7514c24892. Subsequent calls will reuse this data.\n"
          ]
        }
      ],
      "source": [
        "quac_dt = load_dataset('../input/squadlikeloader/squad_like.py', data_files={'validation':'../quactosquad/quac_val.json', 'train':'../quactosquad/quac_val.json'}, split='validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "347258fb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-12T14:08:34.383360Z",
          "iopub.status.busy": "2022-03-12T14:08:34.382583Z",
          "iopub.status.idle": "2022-03-12T14:08:36.092171Z",
          "shell.execute_reply": "2022-03-12T14:08:36.092889Z",
          "shell.execute_reply.started": "2022-03-03T21:08:39.423151Z"
        },
        "papermill": {
          "duration": 1.754859,
          "end_time": "2022-03-12T14:08:36.093106",
          "exception": false,
          "start_time": "2022-03-12T14:08:34.338247",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "133e87a23ca14cec9d068a1bedc1c9df",
            "7a19a26b270b46ac8681d69b4ccee266"
          ]
        },
        "id": "347258fb",
        "outputId": "2efe2322-2e42-4eb7-c1e6-76d37d3a0388"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset squad_like/default to /root/.cache/huggingface/datasets/squad_like/default-440ce43c40204aae/0.0.0/c11bde73ef00f53b085b6a086d13514938f65b80af061fc874ce3e7514c24892...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "133e87a23ca14cec9d068a1bedc1c9df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a19a26b270b46ac8681d69b4ccee266",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset squad_like downloaded and prepared to /root/.cache/huggingface/datasets/squad_like/default-440ce43c40204aae/0.0.0/c11bde73ef00f53b085b6a086d13514938f65b80af061fc874ce3e7514c24892. Subsequent calls will reuse this data.\n"
          ]
        }
      ],
      "source": [
        "newsqa_dt = load_dataset('../input/squadlikeloader/squad_like.py', data_files={'validation':'../newsqatosquad/newsqa_dev.json', 'train':'../newsqatosquad/newsqa_dev.json'}, split='validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d6f53e3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-12T14:08:36.185962Z",
          "iopub.status.busy": "2022-03-12T14:08:36.184410Z",
          "iopub.status.idle": "2022-03-12T14:08:36.186585Z",
          "shell.execute_reply": "2022-03-12T14:08:36.186994Z",
          "shell.execute_reply.started": "2022-03-03T21:08:39.585021Z"
        },
        "papermill": {
          "duration": 0.048434,
          "end_time": "2022-03-12T14:08:36.187145",
          "exception": false,
          "start_time": "2022-03-12T14:08:36.138711",
          "status": "completed"
        },
        "tags": [],
        "id": "4d6f53e3"
      },
      "outputs": [],
      "source": [
        "eval_datasets = {\n",
        "    'SQuADv2' : squad_dt, \n",
        "    'TriviaQA' : triviaqa_dt,\n",
        "    'NQ' : nq_dt,\n",
        "    'QuAC' : quac_dt,\n",
        "    'NewsQA' : newsqa_dt,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess datasets"
      ],
      "metadata": {
        "id": "kTkQs1ygHLsV"
      },
      "id": "kTkQs1ygHLsV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b69381c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-12T14:08:36.274799Z",
          "iopub.status.busy": "2022-03-12T14:08:36.274135Z",
          "iopub.status.idle": "2022-03-12T14:08:42.082215Z",
          "shell.execute_reply": "2022-03-12T14:08:42.081669Z",
          "shell.execute_reply.started": "2022-03-03T21:08:39.725346Z"
        },
        "papermill": {
          "duration": 5.853573,
          "end_time": "2022-03-12T14:08:42.082345",
          "exception": false,
          "start_time": "2022-03-12T14:08:36.228772",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "c15a95d02e464385ac221e1f091a2620",
            "4a4e43ee576248e5b3bb58af72a1eac0",
            "945812c9a4e64ad58cb81907e0e1ad5b",
            "de9484fe2cfd47b79f910d558e8f9793"
          ]
        },
        "id": "8b69381c",
        "outputId": "610fbece-6a33-4f3f-a3cc-f90fcef7a9c0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c15a95d02e464385ac221e1f091a2620",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a4e43ee576248e5b3bb58af72a1eac0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "945812c9a4e64ad58cb81907e0e1ad5b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de9484fe2cfd47b79f910d558e8f9793",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "# initialize the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "MAX_LENGTH = 384\n",
        "DOC_STRIDE = 128 # multi-context overlapping range for large context'd instances "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14f88ad4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-12T14:08:42.184322Z",
          "iopub.status.busy": "2022-03-12T14:08:42.183562Z",
          "iopub.status.idle": "2022-03-12T14:08:42.186042Z",
          "shell.execute_reply": "2022-03-12T14:08:42.185541Z",
          "shell.execute_reply.started": "2022-03-03T21:08:40.869017Z"
        },
        "papermill": {
          "duration": 0.05933,
          "end_time": "2022-03-12T14:08:42.186146",
          "exception": false,
          "start_time": "2022-03-12T14:08:42.126816",
          "status": "completed"
        },
        "tags": [],
        "id": "14f88ad4"
      },
      "outputs": [],
      "source": [
        "def preprocess_squad(examples):\n",
        "  # get the questions and the context\n",
        "  questions = [q.strip() for q in examples[\"question\"]]\n",
        "  context = examples[\"context\"]\n",
        "  # tokenize questions along with the context \n",
        "  inputs = tokenizer(\n",
        "        questions,\n",
        "        context,\n",
        "        max_length=MAX_LENGTH,\n",
        "        stride=DOC_STRIDE,\n",
        "        truncation=\"only_second\",\n",
        "        padding=\"max_length\",\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "    )\n",
        "  offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "  sample_mapping = inputs.pop(\"overflow_to_sample_mapping\")\n",
        "  answers = examples[\"answers\"]\n",
        "  start_positions = []\n",
        "  end_positions = []\n",
        "  \n",
        "  for i, offset in enumerate(offset_mapping):\n",
        "    sample_index = sample_mapping[i]\n",
        "    answer = examples[\"answers\"][sample_index]\n",
        "    # if there is no answer default to [CLS]\n",
        "    if not answer[\"answer_start\"]:\n",
        "      start_positions.append(inputs['input_ids'][i].index(tokenizer.cls_token_id))\n",
        "      end_positions.append(inputs['input_ids'][i].index(tokenizer.cls_token_id))\n",
        "      continue \n",
        "    \n",
        "    # get answer start and end positions\n",
        "    start_char = answer[\"answer_start\"][0]\n",
        "    end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
        "    sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "    # Find the start and end of the context\n",
        "    idx = 0\n",
        "    while sequence_ids[idx] != 1:\n",
        "      idx += 1\n",
        "    context_start = idx\n",
        "    while sequence_ids[idx] == 1:\n",
        "      idx += 1\n",
        "    context_end = idx - 1\n",
        "\n",
        "    # If the answer is not fully inside the context, label it (0, 0)\n",
        "    if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
        "      start_positions.append(inputs['input_ids'][i].index(tokenizer.cls_token_id))\n",
        "      end_positions.append(inputs['input_ids'][i].index(tokenizer.cls_token_id))\n",
        "    else:\n",
        "      # Otherwise it's the start and end token positions\n",
        "      idx = context_start\n",
        "      while idx <= context_end and offset[idx][0] <= start_char:\n",
        "        idx += 1\n",
        "      start_positions.append(idx - 1)\n",
        "\n",
        "      idx = context_end\n",
        "      while idx >= context_start and offset[idx][1] >= end_char:\n",
        "        idx -= 1\n",
        "      end_positions.append(idx + 1)\n",
        "\n",
        "  inputs[\"start_positions\"] = start_positions\n",
        "  inputs[\"end_positions\"] = end_positions\n",
        "  return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "536cd065",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-12T14:08:42.277750Z",
          "iopub.status.busy": "2022-03-12T14:08:42.276958Z",
          "iopub.status.idle": "2022-03-12T14:08:42.279433Z",
          "shell.execute_reply": "2022-03-12T14:08:42.278974Z",
          "shell.execute_reply.started": "2022-03-03T21:08:42.350756Z"
        },
        "papermill": {
          "duration": 0.049792,
          "end_time": "2022-03-12T14:08:42.279548",
          "exception": false,
          "start_time": "2022-03-12T14:08:42.229756",
          "status": "completed"
        },
        "tags": [],
        "id": "536cd065"
      },
      "outputs": [],
      "source": [
        "def appropriate_length(q, c):\n",
        "    tq = tokenizer(q)['input_ids']\n",
        "    return len(tq) <= MAX_LENGTH\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6038369a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-12T14:08:42.372261Z",
          "iopub.status.busy": "2022-03-12T14:08:42.371462Z",
          "iopub.status.idle": "2022-03-12T14:10:22.764633Z",
          "shell.execute_reply": "2022-03-12T14:10:22.765065Z",
          "shell.execute_reply.started": "2022-03-03T21:08:42.470545Z"
        },
        "papermill": {
          "duration": 100.441946,
          "end_time": "2022-03-12T14:10:22.765240",
          "exception": false,
          "start_time": "2022-03-12T14:08:42.323294",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "6b2e30d3120c4894ab631403ee9c2db6",
            "b6c57c826c79499aa99fc5bc0f20bf14",
            "f3075b3794974dfdaea4b0b6a124d78c",
            "573078cf2bcb464dbe0a1eb59d7b9021",
            "e54a3fa9e5e94ee88a585894a35a7870",
            "f01cfacc43fa458b8b7f805c7edd1e25",
            "0725e46e330d4346b2e5d202628f232e",
            "adca0fc7aa184405aef6599e17e7ccd0",
            "81fc919d48fe41d9a52a4659872dfcb9",
            "05eab15ece5845b288ac7ae1f2e7387e"
          ]
        },
        "id": "6038369a",
        "outputId": "abf049af-f7a5-4a6c-ead3-33d460a5b509"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b2e30d3120c4894ab631403ee9c2db6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/12 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6c57c826c79499aa99fc5bc0f20bf14",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/12 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3075b3794974dfdaea4b0b6a124d78c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/15 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "573078cf2bcb464dbe0a1eb59d7b9021",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/15 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e54a3fa9e5e94ee88a585894a35a7870",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f01cfacc43fa458b8b7f805c7edd1e25",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0725e46e330d4346b2e5d202628f232e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/8 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "adca0fc7aa184405aef6599e17e7ccd0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/8 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81fc919d48fe41d9a52a4659872dfcb9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05eab15ece5845b288ac7ae1f2e7387e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for dt_id in eval_datasets:\n",
        "    eval_datasets[dt_id] = eval_datasets[dt_id].filter(appropriate_length, input_columns=['question', 'context']) # make sure that the questions cannot get segmented\n",
        "    eval_datasets[dt_id] = eval_datasets[dt_id].map(preprocess_squad, batched=True, remove_columns=eval_datasets[dt_id].column_names) # preprocess the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5ae26a8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-12T14:10:22.870241Z",
          "iopub.status.busy": "2022-03-12T14:10:22.868719Z",
          "iopub.status.idle": "2022-03-12T14:10:22.870892Z",
          "shell.execute_reply": "2022-03-12T14:10:22.871340Z",
          "shell.execute_reply.started": "2022-03-03T20:39:40.431304Z"
        },
        "papermill": {
          "duration": 0.05665,
          "end_time": "2022-03-12T14:10:22.871480",
          "exception": false,
          "start_time": "2022-03-12T14:10:22.814830",
          "status": "completed"
        },
        "tags": [],
        "id": "c5ae26a8"
      },
      "outputs": [],
      "source": [
        "eval_loaders = {\n",
        "    key : torch.utils.data.DataLoader(value, batch_size=24, shuffle=True) for key, value in eval_datasets.items()\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation Phase\n",
        "\n",
        "Use the default mertics for squad-formated datasets' evaluation, from the huggingface hub, using the load\\_metric() routine."
      ],
      "metadata": {
        "id": "TN7e_lfoHO-N"
      },
      "id": "TN7e_lfoHO-N"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f645544",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-12T14:10:23.097499Z",
          "iopub.status.busy": "2022-03-12T14:10:23.092838Z",
          "iopub.status.idle": "2022-03-12T16:08:24.012582Z",
          "shell.execute_reply": "2022-03-12T16:08:24.011958Z",
          "shell.execute_reply.started": "2022-03-03T21:00:16.168728Z"
        },
        "papermill": {
          "duration": 7080.980876,
          "end_time": "2022-03-12T16:08:24.012743",
          "exception": false,
          "start_time": "2022-03-12T14:10:23.031867",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "ce55ee4d7fac445d82bcb4c01ee5b481",
            "095f8dfc2e3f4890a532379b218b826c",
            "aa64e0245eb24831984e0e1973cd9099",
            "992d00313b854c9d8dd49181e337c81b",
            "54cfa7fa56494194829ad439c72e2668",
            "0cc42b3735a842d7b1700a0ac89ba580",
            "6c37d23cfb464ec9a0e661e2c57e3af9",
            "1db06846f3a64d268baa5abdcc0f9c24",
            "a83028fa913a40a9997790614dbb1cf9",
            "007955dd526c42e686b72ad945007505",
            "e73aa28578f7418b94850ca465e867ee",
            "76770e70d995495f981fc529fcbfc6a8"
          ]
        },
        "id": "6f645544",
        "outputId": "ae86a06d-5935-4226-e1bb-b25865eff510"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce55ee4d7fac445d82bcb4c01ee5b481",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/673 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "095f8dfc2e3f4890a532379b218b826c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/415M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa64e0245eb24831984e0e1973cd9099",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.25k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "992d00313b854c9d8dd49181e337c81b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/3.18k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 506/506 [03:06<00:00,  2.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert-on-squad2 on SQuADv2: exact:64.58711059831877, f1:70.54734852507852\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2222/2222 [13:09<00:00,  2.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert-on-squad2 on TriviaQA: exact:63.72824782478248, f1:64.83328227310953\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 143/143 [00:50<00:00,  2.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert-on-squad2 on NQ: exact:31.673014942865514, f1:38.958448587651986\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 307/307 [01:49<00:00,  2.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert-on-squad2 on QuAC: exact:33.763937992929016, f1:36.02606995687384\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 707/707 [04:11<00:00,  2.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert-on-squad2 on NewsQA: exact:55.569963456324416, f1:58.96617328644258\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54cfa7fa56494194829ad439c72e2668",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/673 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0cc42b3735a842d7b1700a0ac89ba580",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/415M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 506/506 [03:01<00:00,  2.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert-finetuned-triviaqa on SQuADv2: exact:36.12164166804022, f1:39.30426229875678\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2222/2222 [13:12<00:00,  2.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert-finetuned-triviaqa on TriviaQA: exact:71.43339333933393, f1:72.28513363883935\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 143/143 [00:51<00:00,  2.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert-finetuned-triviaqa on NQ: exact:33.78259595663639, f1:38.46840835592722\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 307/307 [01:49<00:00,  2.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert-finetuned-triviaqa on QuAC: exact:55.085667663856405, f1:55.7392841931602\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 707/707 [04:12<00:00,  2.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert-finetuned-triviaqa on NewsQA: exact:57.10833431569021, f1:59.07536924605947\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c37d23cfb464ec9a0e661e2c57e3af9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/673 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1db06846f3a64d268baa5abdcc0f9c24",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/415M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 506/506 [03:01<00:00,  2.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert-finetuned-nq on SQuADv2: exact:40.843909675292565, f1:44.44707749685987\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2222/2222 [13:17<00:00,  2.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert-finetuned-nq on TriviaQA: exact:54.911116111611165, f1:56.44004324960148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 143/143 [00:51<00:00,  2.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert-finetuned-nq on NQ: exact:53.472018751831236, f1:61.2643776520415\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 307/307 [01:51<00:00,  2.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert-finetuned-nq on QuAC: exact:59.260266521620885, f1:59.96489244864429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 707/707 [04:14<00:00,  2.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert-finetuned-nq on NewsQA: exact:57.33820582341153, f1:59.331982155382995\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a83028fa913a40a9997790614dbb1cf9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/673 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "007955dd526c42e686b72ad945007505",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/415M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 506/506 [03:02<00:00,  2.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert-finetuned-quac on SQuADv2: exact:27.385857919894512, f1:28.41310490914049\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2222/2222 [13:14<00:00,  2.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert-finetuned-quac on TriviaQA: exact:56.85756075607561, f1:56.98147817316199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 143/143 [00:51<00:00,  2.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert-finetuned-quac on NQ: exact:14.38617052446528, f1:16.59844053954373\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 307/307 [01:50<00:00,  2.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert-finetuned-quac on QuAC: exact:50.53032363339679, f1:53.979574641934704\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 707/707 [04:13<00:00,  2.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert-finetuned-quac on NewsQA: exact:48.85064246139338, f1:49.16474056003159\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e73aa28578f7418b94850ca465e867ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/673 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76770e70d995495f981fc529fcbfc6a8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/415M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 506/506 [03:01<00:00,  2.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert-finetuned-newsqa on SQuADv2: exact:22.03725070051096, f1:31.61951532935127\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2222/2222 [13:16<00:00,  2.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert-finetuned-newsqa on TriviaQA: exact:5.683693369336933, f1:7.964988250103812\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 143/143 [00:51<00:00,  2.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert-finetuned-newsqa on NQ: exact:27.746850278347495, f1:39.20854602167326\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 307/307 [01:50<00:00,  2.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert-finetuned-newsqa on QuAC: exact:0.013598041881968996, f1:4.149837385465861\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 707/707 [04:13<00:00,  2.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert-finetuned-newsqa on NewsQA: exact:16.45644229635742, f1:22.056876688079935\n"
          ]
        }
      ],
      "source": [
        "for model_name in ['bert-on-squad2', 'bert-finetuned-triviaqa', 'bert-finetuned-nq', 'bert-finetuned-quac', 'bert-finetuned-newsqa']:\n",
        "    model = AutoModelForQuestionAnswering.from_pretrained('vissa/'+model_name, use_auth_token=token)\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    metric = load_metric('squad_v2')\n",
        "    for test_set, test_loader in eval_loaders.items():\n",
        "        f1_total = []\n",
        "        acc = []\n",
        "        test_loss = []\n",
        "        acc = []\n",
        "        pbar = tqdm(test_loader)\n",
        "        for i,batch in enumerate(pbar):\n",
        "          torch.cuda.empty_cache()\n",
        "          with torch.no_grad():\n",
        "            args = {\n",
        "                  \"start_positions\" : torch.LongTensor(batch[\"start_positions\"]).to(device),\n",
        "                  \"end_positions\" : torch.LongTensor(batch[\"end_positions\"]).to(device),\n",
        "                  \"input_ids\" : torch.stack(batch[\"input_ids\"], axis=1).to(device),\n",
        "                  \"attention_mask\" : torch.stack(batch[\"attention_mask\"], axis=1).to(device)\n",
        "                }\n",
        "            outputs = model(**args)\n",
        "            test_loss.append(outputs[0].item())\n",
        "            # find the indices for start and end in every example of the batch\n",
        "            start_positions = []\n",
        "            end_positions = []\n",
        "            start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
        "            end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
        "\n",
        "            # create tokens lists and estimate f1 score based on common tokens, since its the same as estimating the f1 based on common words\n",
        "            pred = [tokenizer.decode(input_ids[s:e+1].tolist()) for input_ids, (s, e) in zip(args['input_ids'], zip(start_pred, end_pred))]\n",
        "            true = [tokenizer.decode(input_ids[s:e+1].tolist()) for input_ids, (s, e) in zip(args['input_ids'], zip(args['start_positions'], args['end_positions']))]\n",
        "            # calculate exact match\n",
        "#             acc.append(compute_exact(pred_token_ranges, true_token_ranges))\n",
        "\n",
        "#             f1_total.append(compute_f1(pred_token_ranges, true_token_ranges))\n",
        "            metric.add_batch(predictions=[{'id':24*i+id, 'prediction_text':text, 'no_answer_probability':0.0} for id,text in enumerate(pred)], \n",
        "                             references=[{'id':24*i+id, 'answers':{'text':[text], 'answer_start':[args['start_positions'][id]]}} for id,text in enumerate(true)])\n",
        "        cur = test_set,metric.compute()\n",
        "        print('{} on {}: exact:{}, f1:{}'.format(model_name, test_set, cur[1]['exact'], cur[1]['f1']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "920ef8c9",
      "metadata": {
        "papermill": {
          "duration": 6.343155,
          "end_time": "2022-03-12T16:08:36.451368",
          "exception": false,
          "start_time": "2022-03-12T16:08:30.108213",
          "status": "completed"
        },
        "tags": [],
        "id": "920ef8c9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8be09088",
      "metadata": {
        "papermill": {
          "duration": 6.334284,
          "end_time": "2022-03-12T16:08:49.345824",
          "exception": false,
          "start_time": "2022-03-12T16:08:43.011540",
          "status": "completed"
        },
        "tags": [],
        "id": "8be09088"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 7285.55481,
      "end_time": "2022-03-12T16:08:59.359730",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-03-12T14:07:33.804920",
      "version": "2.3.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    },
    "colab": {
      "name": "eval-bert-all.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}