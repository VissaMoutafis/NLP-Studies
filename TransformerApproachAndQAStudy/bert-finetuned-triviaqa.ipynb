{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "18eb59d7",
      "metadata": {
        "papermill": {
          "duration": 0.021374,
          "end_time": "2022-02-28T21:54:40.490003",
          "exception": false,
          "start_time": "2022-02-28T21:54:40.468629",
          "status": "completed"
        },
        "tags": [],
        "id": "18eb59d7"
      },
      "source": [
        "# Finetune Bert on TriviaQA\n",
        "**Student Credentials:** sdi1800119, Vissarion Moutafis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f03bcbd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-28T21:54:40.533666Z",
          "iopub.status.busy": "2022-02-28T21:54:40.532164Z",
          "iopub.status.idle": "2022-02-28T21:55:07.546547Z",
          "shell.execute_reply": "2022-02-28T21:55:07.545977Z",
          "shell.execute_reply.started": "2022-02-28T21:51:23.744591Z"
        },
        "papermill": {
          "duration": 27.036519,
          "end_time": "2022-02-28T21:55:07.546695",
          "exception": false,
          "start_time": "2022-02-28T21:54:40.510176",
          "status": "completed"
        },
        "tags": [],
        "id": "4f03bcbd",
        "outputId": "7931c3c7-141c-4836-afbe-b46923d646c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.15.0)\r\n",
            "Collecting datasets\r\n",
            "  Downloading datasets-1.18.3-py3-none-any.whl (311 kB)\r\n",
            "     |████████████████████████████████| 311 kB 769 kB/s            \r\n",
            "\u001b[?25hRequirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.3)\r\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\r\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.4.2)\r\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.20.3)\r\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\r\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.2.1)\r\n",
            "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.47)\r\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.26.0)\r\n",
            "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.62.3)\r\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\r\n",
            "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.10.1)\r\n",
            "Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.4)\r\n",
            "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.12.2)\r\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2022.1.0)\r\n",
            "Collecting xxhash\r\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\r\n",
            "     |████████████████████████████████| 212 kB 11.9 MB/s            \r\n",
            "\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\r\n",
            "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.1)\r\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (6.0.1)\r\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.0.1)\r\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.6)\r\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.7)\r\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.0.9)\r\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2021.10.8)\r\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.1)\r\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\r\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.1)\r\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\r\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.7.2)\r\n",
            "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\r\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (21.2.0)\r\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (5.2.0)\r\n",
            "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.6.0)\r\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\r\n",
            "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2021.3)\r\n",
            "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.1.0)\r\n",
            "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.3)\r\n",
            "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\r\n",
            "Installing collected packages: xxhash, datasets\r\n",
            "Successfully installed datasets-1.18.3 xxhash-3.0.0\r\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "The following NEW packages will be installed:\r\n",
            "  git-lfs\r\n",
            "0 upgraded, 1 newly installed, 0 to remove and 42 not upgraded.\r\n",
            "Need to get 3316 kB of archives.\r\n",
            "After this operation, 11.1 MB of additional disk space will be used.\r\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 git-lfs amd64 2.9.2-1 [3316 kB]\r\n",
            "Fetched 3316 kB in 1s (2237 kB/s)\r\n",
            "\n",
            "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package git-lfs.\r\n",
            "(Reading database ... 103272 files and directories currently installed.)\r\n",
            "Preparing to unpack .../git-lfs_2.9.2-1_amd64.deb ...\r\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 20%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Unpacking git-lfs (2.9.2-1) ...\r\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 40%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Setting up git-lfs (2.9.2-1) ...\r\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 60%]\u001b[49m\u001b[39m [##################################........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 80%]\u001b[49m\u001b[39m [##############################################............] \u001b8Processing triggers for man-db (2.9.1-1) ...\r\n",
            "\r\n",
            "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[JRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (4.62.3)\r\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn\n",
        "import re\n",
        "seaborn.set_style(\"ticks\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve, auc, classification_report\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchtext\n",
        "from torch.utils.data import SubsetRandomSampler\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "!pip install transformers datasets\n",
        "!apt install git-lfs\n",
        "import transformers\n",
        "import datasets\n",
        "from transformers import AutoModel, BertTokenizer, BertForSequenceClassification, AutoModelForSequenceClassification, AutoModelForQuestionAnswering\n",
        "from datasets import load_dataset, load_metric\n",
        "\n",
        "!pip install tqdm\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0ad50a3",
      "metadata": {
        "papermill": {
          "duration": 0.03295,
          "end_time": "2022-02-28T21:55:07.614277",
          "exception": false,
          "start_time": "2022-02-28T21:55:07.581327",
          "status": "completed"
        },
        "tags": [],
        "id": "e0ad50a3"
      },
      "source": [
        "## Load the model and dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc274503",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-28T21:55:07.685219Z",
          "iopub.status.busy": "2022-02-28T21:55:07.684672Z",
          "iopub.status.idle": "2022-02-28T21:55:07.687236Z",
          "shell.execute_reply": "2022-02-28T21:55:07.687604Z",
          "shell.execute_reply.started": "2022-02-28T21:51:40.612663Z"
        },
        "papermill": {
          "duration": 0.040418,
          "end_time": "2022-02-28T21:55:07.687724",
          "exception": false,
          "start_time": "2022-02-28T21:55:07.647306",
          "status": "completed"
        },
        "tags": [],
        "id": "dc274503"
      },
      "outputs": [],
      "source": [
        "model_checkpoint = 'bert-base-uncased'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99c6c1cc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-28T21:55:07.759570Z",
          "iopub.status.busy": "2022-02-28T21:55:07.759081Z",
          "iopub.status.idle": "2022-02-28T21:55:34.008583Z",
          "shell.execute_reply": "2022-02-28T21:55:34.009031Z",
          "shell.execute_reply.started": "2022-02-28T21:51:40.618854Z"
        },
        "papermill": {
          "duration": 26.288484,
          "end_time": "2022-02-28T21:55:34.009196",
          "exception": false,
          "start_time": "2022-02-28T21:55:07.720712",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "ac3e05b508d3478fb13547ba17584c08",
            "2b8cc9c11a2c4b68875fca2c947ab0ca"
          ]
        },
        "id": "99c6c1cc",
        "outputId": "a6fdfa3a-e7bc-4ba5-df58-644a70ef216b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset squad_like/default to /root/.cache/huggingface/datasets/squad_like/default-57224fdc8b8ea94a/0.0.0/c11bde73ef00f53b085b6a086d13514938f65b80af061fc874ce3e7514c24892...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac3e05b508d3478fb13547ba17584c08",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b8cc9c11a2c4b68875fca2c947ab0ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset squad_like downloaded and prepared to /root/.cache/huggingface/datasets/squad_like/default-57224fdc8b8ea94a/0.0.0/c11bde73ef00f53b085b6a086d13514938f65b80af061fc874ce3e7514c24892. Subsequent calls will reuse this data.\n"
          ]
        }
      ],
      "source": [
        "train_dataset = load_dataset('../input/squadlikeloader/squad_like.py', data_files={'train':'../triviaqatosquad/triviaqa_train.json', 'validation':'../triviaqatosquad/triviaqa_dev.json'}, split='train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33eaa9eb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-28T21:55:34.082402Z",
          "iopub.status.busy": "2022-02-28T21:55:34.081611Z",
          "iopub.status.idle": "2022-02-28T21:55:49.797917Z",
          "shell.execute_reply": "2022-02-28T21:55:49.798326Z",
          "shell.execute_reply.started": "2022-02-28T21:51:40.655476Z"
        },
        "papermill": {
          "duration": 15.753919,
          "end_time": "2022-02-28T21:55:49.798496",
          "exception": false,
          "start_time": "2022-02-28T21:55:34.044577",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "027a411c5e5c47c3a64a34994011ddd8",
            "d60ebc4b19e34242a4b5c985a0bff1d3",
            "b04bb230f6a04ac2bbc4b05249773711",
            "a8adc18480704a519d5f2a74f76d2743",
            "e67ed46dbe934fed9445358a72603e31",
            "263df7bcac9c48a28372e1c85f0b49a3",
            "4560036b1ab44c2c86100ce7c535df94",
            "bfa95737e7ef4e6ea57a976ac30376cc"
          ]
        },
        "id": "33eaa9eb",
        "outputId": "da474f8b-e70b-48ea-8533-456e87afef3f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "027a411c5e5c47c3a64a34994011ddd8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.87k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d60ebc4b19e34242a4b5c985a0bff1d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset squad_v2/squad_v2 (download: 44.34 MiB, generated: 122.41 MiB, post-processed: Unknown size, total: 166.75 MiB) to /root/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b04bb230f6a04ac2bbc4b05249773711",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8adc18480704a519d5f2a74f76d2743",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/9.55M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e67ed46dbe934fed9445358a72603e31",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/801k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "263df7bcac9c48a28372e1c85f0b49a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4560036b1ab44c2c86100ce7c535df94",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bfa95737e7ef4e6ea57a976ac30376cc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset squad_v2 downloaded and prepared to /root/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d. Subsequent calls will reuse this data.\n"
          ]
        }
      ],
      "source": [
        "test_dataset = load_dataset('squad_v2', split='validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48d8815e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-28T21:55:49.892873Z",
          "iopub.status.busy": "2022-02-28T21:55:49.892142Z",
          "iopub.status.idle": "2022-02-28T21:55:55.716079Z",
          "shell.execute_reply": "2022-02-28T21:55:55.715173Z",
          "shell.execute_reply.started": "2022-02-28T21:51:41.478892Z"
        },
        "papermill": {
          "duration": 5.871996,
          "end_time": "2022-02-28T21:55:55.716245",
          "exception": false,
          "start_time": "2022-02-28T21:55:49.844249",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "b69bedfb2ab04c5b99cba7f5755600ab",
            "16fbd33bee214b498454293725f6b3a4",
            "03ace7852b5c4908b1051feb7adf687c",
            "7664e21a9b84442ab5c652615c64609d"
          ]
        },
        "id": "48d8815e",
        "outputId": "6954f9cb-036a-433d-887d-469e4888b03a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b69bedfb2ab04c5b99cba7f5755600ab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16fbd33bee214b498454293725f6b3a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03ace7852b5c4908b1051feb7adf687c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7664e21a9b84442ab5c652615c64609d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "# initialize the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "MAX_LENGTH = 384\n",
        "DOC_STRIDE = 128 # multi-context overlapping range for large context'd instances \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8dbc4d3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-28T21:55:55.814682Z",
          "iopub.status.busy": "2022-02-28T21:55:55.813815Z",
          "iopub.status.idle": "2022-02-28T21:55:55.815727Z",
          "shell.execute_reply": "2022-02-28T21:55:55.816129Z",
          "shell.execute_reply.started": "2022-02-28T21:51:45.233589Z"
        },
        "papermill": {
          "duration": 0.05622,
          "end_time": "2022-02-28T21:55:55.816262",
          "exception": false,
          "start_time": "2022-02-28T21:55:55.760042",
          "status": "completed"
        },
        "tags": [],
        "id": "c8dbc4d3"
      },
      "outputs": [],
      "source": [
        "def preprocess_squad(examples):\n",
        "  # get the questions and the context\n",
        "  questions = [q.strip() for q in examples[\"question\"]]\n",
        "  context = examples[\"context\"]\n",
        "  # tokenize questions along with the context \n",
        "  inputs = tokenizer(\n",
        "        questions,\n",
        "        context,\n",
        "        max_length=MAX_LENGTH,\n",
        "        stride=DOC_STRIDE,\n",
        "        truncation=\"only_second\",\n",
        "        padding=\"max_length\",\n",
        "        return_offsets_mapping=True,\n",
        "        return_overflowing_tokens=True\n",
        "    )\n",
        "  offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "  sample_mapping = inputs.pop(\"overflow_to_sample_mapping\")\n",
        "  answers = examples[\"answers\"]\n",
        "  start_positions = []\n",
        "  end_positions = []\n",
        "  \n",
        "  for i, offset in enumerate(offset_mapping):\n",
        "    sample_index = sample_mapping[i]\n",
        "    answer = examples[\"answers\"][sample_index]\n",
        "    # if there is no answer default to [CLS]\n",
        "    if not answer[\"answer_start\"]:\n",
        "      start_positions.append(inputs['input_ids'][i].index(tokenizer.cls_token_id))\n",
        "      end_positions.append(inputs['input_ids'][i].index(tokenizer.cls_token_id))\n",
        "      continue \n",
        "    \n",
        "    # get answer start and end positions\n",
        "    start_char = answer[\"answer_start\"][0]\n",
        "    end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
        "    sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "    # Find the start and end of the context\n",
        "    idx = 0\n",
        "    while sequence_ids[idx] != 1:\n",
        "      idx += 1\n",
        "    context_start = idx\n",
        "    while sequence_ids[idx] == 1:\n",
        "      idx += 1\n",
        "    context_end = idx - 1\n",
        "\n",
        "    # If the answer is not fully inside the context, label it (0, 0)\n",
        "    if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
        "#       start_positions.append(inputs['input_ids'][i].index(tokenizer.cls_token_id))\n",
        "#       end_positions.append(inputs['input_ids'][i].index(tokenizer.cls_token_id))\n",
        "      start_positions.append(-1)\n",
        "      end_positions.append(-1)\n",
        "    else:\n",
        "      # Otherwise it's the start and end token positions\n",
        "      idx = context_start\n",
        "      while idx <= context_end and offset[idx][0] <= start_char:\n",
        "        idx += 1\n",
        "      start_positions.append(idx - 1)\n",
        "\n",
        "      idx = context_end\n",
        "      while idx >= context_start and offset[idx][1] >= end_char:\n",
        "        idx -= 1\n",
        "      end_positions.append(idx + 1)\n",
        "\n",
        "  inputs[\"start_positions\"] = start_positions\n",
        "  inputs[\"end_positions\"] = end_positions\n",
        "  return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18297efb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-28T21:55:55.906140Z",
          "iopub.status.busy": "2022-02-28T21:55:55.905374Z",
          "iopub.status.idle": "2022-02-28T21:56:11.690783Z",
          "shell.execute_reply": "2022-02-28T21:56:11.690245Z",
          "shell.execute_reply.started": "2022-02-28T21:51:45.250011Z"
        },
        "papermill": {
          "duration": 15.833175,
          "end_time": "2022-02-28T21:56:11.690938",
          "exception": false,
          "start_time": "2022-02-28T21:55:55.857763",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "cd5815f7c27b485782e495ebc5770587",
            "2feaf27978974d008b2800ca4d73a6b8"
          ]
        },
        "id": "18297efb",
        "outputId": "4ddc5a7d-2d48-46c4-bff0-dda1d031abb3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd5815f7c27b485782e495ebc5770587",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/111 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2feaf27978974d008b2800ca4d73a6b8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/12 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def appropriate_length(q, c):\n",
        "#     if len(q) + 3 >= DOC_STRIDE:\n",
        "#         print(q)\n",
        "    tq = tokenizer(q)['input_ids']\n",
        "    return len(tq) <= DOC_STRIDE\n",
        "\n",
        "train_dataset = train_dataset.filter(appropriate_length, input_columns=['question', 'context'])\n",
        "test_dataset = test_dataset.filter(appropriate_length, input_columns=['question', 'context'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "422decd3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-28T21:56:11.800275Z",
          "iopub.status.busy": "2022-02-28T21:56:11.799504Z",
          "iopub.status.idle": "2022-02-28T22:03:21.656119Z",
          "shell.execute_reply": "2022-02-28T22:03:21.655505Z",
          "shell.execute_reply.started": "2022-02-28T21:51:45.281166Z"
        },
        "papermill": {
          "duration": 429.919592,
          "end_time": "2022-02-28T22:03:21.656323",
          "exception": false,
          "start_time": "2022-02-28T21:56:11.736731",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "9bdc718042ce494584c52db148393834",
            "cbabbdc8b2c9494c9f0a8ac4998bf16c"
          ]
        },
        "id": "422decd3",
        "outputId": "20fc0c9e-fb74-4a19-df73-6ca1a5fa2824"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9bdc718042ce494584c52db148393834",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/111 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cbabbdc8b2c9494c9f0a8ac4998bf16c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/12 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_dataset = train_dataset.map(preprocess_squad, batched=True, remove_columns=train_dataset.column_names)\n",
        "test_dataset = test_dataset.map(preprocess_squad, batched=True, remove_columns=test_dataset.column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14d6b1e2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-28T22:03:21.770772Z",
          "iopub.status.busy": "2022-02-28T22:03:21.749442Z",
          "iopub.status.idle": "2022-02-28T22:03:22.776542Z",
          "shell.execute_reply": "2022-02-28T22:03:22.776117Z",
          "shell.execute_reply.started": "2022-02-28T21:52:10.908824Z"
        },
        "papermill": {
          "duration": 1.076722,
          "end_time": "2022-02-28T22:03:22.776673",
          "exception": false,
          "start_time": "2022-02-28T22:03:21.699951",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "bd4c36989ca449b1b7a768ef56c7ecfa",
            "a8392ce87dc24298819843b86e5d84e0"
          ]
        },
        "id": "14d6b1e2",
        "outputId": "3324dea6-ed38-4c8b-ff4f-d53ddef35b37"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd4c36989ca449b1b7a768ef56c7ecfa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/415 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8392ce87dc24298819843b86e5d84e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/13 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def is_valid(s, e):\n",
        "    return s != -1 and e != -1\n",
        "\n",
        "train_dataset = train_dataset.filter(is_valid, input_columns=['start_positions', 'end_positions'])\n",
        "test_dataset = test_dataset.filter(is_valid, input_columns=['start_positions', 'end_positions'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b83472f",
      "metadata": {
        "papermill": {
          "duration": 0.043699,
          "end_time": "2022-02-28T22:03:22.865662",
          "exception": false,
          "start_time": "2022-02-28T22:03:22.821963",
          "status": "completed"
        },
        "tags": [],
        "id": "1b83472f"
      },
      "source": [
        "## Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23176ac6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-28T22:03:22.957982Z",
          "iopub.status.busy": "2022-02-28T22:03:22.957324Z",
          "iopub.status.idle": "2022-02-28T22:03:22.959885Z",
          "shell.execute_reply": "2022-02-28T22:03:22.959426Z",
          "shell.execute_reply.started": "2022-02-28T21:52:11.347140Z"
        },
        "papermill": {
          "duration": 0.050491,
          "end_time": "2022-02-28T22:03:22.960000",
          "exception": false,
          "start_time": "2022-02-28T22:03:22.909509",
          "status": "completed"
        },
        "tags": [],
        "id": "23176ac6"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=24, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=24, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be93d473",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-28T22:03:23.054618Z",
          "iopub.status.busy": "2022-02-28T22:03:23.053906Z",
          "iopub.status.idle": "2022-02-28T22:03:34.973390Z",
          "shell.execute_reply": "2022-02-28T22:03:34.973766Z",
          "shell.execute_reply.started": "2022-02-28T21:52:11.724701Z"
        },
        "papermill": {
          "duration": 11.970205,
          "end_time": "2022-02-28T22:03:34.973962",
          "exception": false,
          "start_time": "2022-02-28T22:03:23.003757",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "b5a2ebf23ff34205b186ea0aef975352"
          ]
        },
        "id": "be93d473",
        "outputId": "58404467-ecff-4a33-ef3b-cc13b9c6a044"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b5a2ebf23ff34205b186ea0aef975352",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e433170f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-28T22:03:35.068671Z",
          "iopub.status.busy": "2022-02-28T22:03:35.067904Z",
          "iopub.status.idle": "2022-02-28T22:03:37.723471Z",
          "shell.execute_reply": "2022-02-28T22:03:37.722508Z",
          "shell.execute_reply.started": "2022-02-28T21:52:14.205433Z"
        },
        "papermill": {
          "duration": 2.704038,
          "end_time": "2022-02-28T22:03:37.723600",
          "exception": false,
          "start_time": "2022-02-28T22:03:35.019562",
          "status": "completed"
        },
        "tags": [],
        "id": "e433170f",
        "outputId": "5577276d-674b-4d10-9249-f14fbcfdd410"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertForQuestionAnswering(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "model.to(device)\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bde526e0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-28T22:03:37.835206Z",
          "iopub.status.busy": "2022-02-28T22:03:37.834422Z",
          "iopub.status.idle": "2022-02-28T22:03:37.837086Z",
          "shell.execute_reply": "2022-02-28T22:03:37.836648Z",
          "shell.execute_reply.started": "2022-02-28T21:52:14.824144Z"
        },
        "papermill": {
          "duration": 0.067342,
          "end_time": "2022-02-28T22:03:37.837192",
          "exception": false,
          "start_time": "2022-02-28T22:03:37.769850",
          "status": "completed"
        },
        "tags": [],
        "id": "bde526e0"
      },
      "outputs": [],
      "source": [
        "def training_step(model, optimizer, epoch_i, train_loader, history=None):\n",
        "  torch.cuda.empty_cache()\n",
        "  # 1 step of backprop with train/test error estimation\n",
        "  total_loss = 0\n",
        "  acc = []\n",
        "  pbar = tqdm(train_loader)\n",
        "  for i,batch in enumerate(pbar):\n",
        "    torch.cuda.empty_cache()\n",
        "    # set the gradients to zero for new estimation\n",
        "    optimizer.zero_grad() \n",
        "    # forward pass\n",
        "    args = {\n",
        "        \"start_positions\" : torch.LongTensor(batch[\"start_positions\"]).to(device),\n",
        "        \"end_positions\" : torch.LongTensor(batch[\"end_positions\"]).to(device),\n",
        "        \"input_ids\" : torch.stack(batch[\"input_ids\"], axis=1).to(device),\n",
        "        \"attention_mask\" : torch.stack(batch[\"attention_mask\"], axis=1).to(device),\n",
        "    }\n",
        "    outputs = model(**args) \n",
        "    loss = outputs[0]\n",
        "    start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
        "    end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
        "    # compute loss \n",
        "    total_loss += loss.item()\n",
        "\n",
        "    # backpropagate error\n",
        "    loss.backward()\n",
        "    # apply gradient clipping adjust model's parameters\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
        "    optimizer.step()\n",
        "    \n",
        "    acc.append(((start_pred == args['start_positions']).sum()/len(start_pred)).item())\n",
        "    acc.append(((end_pred == args['end_positions']).sum()/len(end_pred)).item())\n",
        "    pbar.set_description('Epoch {}: train loss: {}, train accuracy: {}%'.format(epoch_i, total_loss/(i+1), sum(acc)/len(acc)), refresh=True)\n",
        "    \n",
        "  train_loss = total_loss/len(train_loader)\n",
        "    \n",
        "    # if the user provides with a history dict the training step will save the current epoch's train-test loss\n",
        "  if history is not None: \n",
        "    history['train'].append(train_loss)\n",
        "  \n",
        "  test_loss = 0\n",
        "  acc = []\n",
        "  pbar = tqdm(test_loader)\n",
        "  for i,batch in enumerate(pbar):\n",
        "    torch.cuda.empty_cache()\n",
        "    with torch.no_grad():\n",
        "      args = {\n",
        "          \"start_positions\" : torch.LongTensor(batch[\"start_positions\"]).to(device),\n",
        "          \"end_positions\" : torch.LongTensor(batch[\"end_positions\"]).to(device),\n",
        "          \"input_ids\" : torch.stack(batch[\"input_ids\"], axis=1).to(device),\n",
        "          \"attention_mask\" : torch.stack(batch[\"attention_mask\"], axis=1).to(device)\n",
        "        }\n",
        "      outputs = model(**args)\n",
        "      test_loss += outputs[0].item()\n",
        "      start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
        "      end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
        "      acc.append(((start_pred == args['start_positions']).sum()/len(start_pred)).item())\n",
        "      acc.append(((end_pred == args['end_positions']).sum()/len(end_pred)).item())\n",
        "      pbar.set_description('Epoch {}: test loss {}%, test accuracy {}%'.format(epoch_i, test_loss/(i+1), sum(acc)/len(acc)), refresh=True)\n",
        "        \n",
        "  if history is not None: \n",
        "    history['test'].append(test_loss/len(test_loader))\n",
        "    \n",
        "\n",
        "  \n",
        "  return train_loss, test_loss/len(test_loader), sum(acc)/len(acc)\n",
        "\n",
        "def train_model(history, model, train_loader, epochs, _lr):\n",
        "  # set to training mode\n",
        "  model.train()\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.AdamW(model.parameters(), lr = _lr)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    training_step(model, optimizer, epoch, train_loader, history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94fccaa1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-28T22:03:37.935414Z",
          "iopub.status.busy": "2022-02-28T22:03:37.934866Z",
          "iopub.status.idle": "2022-03-01T05:02:59.154823Z",
          "shell.execute_reply": "2022-03-01T05:02:59.154121Z",
          "shell.execute_reply.started": "2022-02-28T21:52:14.850843Z"
        },
        "papermill": {
          "duration": 25161.272202,
          "end_time": "2022-03-01T05:02:59.154970",
          "exception": false,
          "start_time": "2022-02-28T22:03:37.882768",
          "status": "completed"
        },
        "tags": [],
        "id": "94fccaa1",
        "outputId": "4a997a0f-e0ce-475d-98b7-6f289c591c53"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 0: train loss: 1.1528560309517641, train accuracy: 0.7187341301697701%: 100%|██████████| 9178/9178 [3:26:29<00:00,  1.35s/it]\n",
            "Epoch 0: test loss 2.5033675871522303%, test accuracy 0.44573097668617845%: 100%|██████████| 502/502 [03:04<00:00,  2.71it/s]\n",
            "Epoch 1: train loss: 0.6666642854907111, train accuracy: 0.816967223936318%: 100%|██████████| 9178/9178 [3:26:41<00:00,  1.35s/it]\n",
            "Epoch 1: test loss 2.8635918813872623%, test accuracy 0.39905656257503297%: 100%|██████████| 502/502 [03:05<00:00,  2.71it/s]\n"
          ]
        }
      ],
      "source": [
        "history = {'train':[], 'test':[]}\n",
        "train_model(history, model, train_loader, 2,  3e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3bd7f47",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-01T05:03:24.943826Z",
          "iopub.status.busy": "2022-03-01T05:03:24.943072Z",
          "iopub.status.idle": "2022-03-01T05:03:26.368905Z",
          "shell.execute_reply": "2022-03-01T05:03:26.368416Z"
        },
        "papermill": {
          "duration": 14.087786,
          "end_time": "2022-03-01T05:03:26.369044",
          "exception": false,
          "start_time": "2022-03-01T05:03:12.281258",
          "status": "completed"
        },
        "tags": [],
        "id": "b3bd7f47",
        "outputId": "7e522158-5c95-4b42-9960-4dfd547aa99b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        }
      ],
      "source": [
        "!mkdir bert-finetuned-triviaqa\n",
        "model.save_pretrained('./bert-finetuned-triviaqa/' , private=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f74e438",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-01T05:03:52.402541Z",
          "iopub.status.busy": "2022-03-01T05:03:52.401959Z",
          "iopub.status.idle": "2022-03-01T05:05:26.601479Z",
          "shell.execute_reply": "2022-03-01T05:05:26.600970Z",
          "shell.execute_reply.started": "2022-02-28T21:52:30.627118Z"
        },
        "papermill": {
          "duration": 107.279848,
          "end_time": "2022-03-01T05:05:26.601612",
          "exception": false,
          "start_time": "2022-03-01T05:03:39.321764",
          "status": "completed"
        },
        "tags": [],
        "id": "2f74e438"
      },
      "outputs": [],
      "source": [
        "model.push_to_hub('vissa/bert-finetuned-triviaqa', use_auth_token='YOUR_WRT_TOKEN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cf5714c",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-28T11:58:50.853201Z",
          "iopub.status.idle": "2022-02-28T11:58:50.854769Z",
          "shell.execute_reply": "2022-02-28T11:58:50.854519Z",
          "shell.execute_reply.started": "2022-02-28T11:58:50.854456Z"
        },
        "papermill": {
          "duration": 12.355451,
          "end_time": "2022-03-01T05:05:51.691259",
          "exception": false,
          "start_time": "2022-03-01T05:05:39.335808",
          "status": "completed"
        },
        "tags": [],
        "id": "5cf5714c"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6440e8b9",
      "metadata": {
        "papermill": {
          "duration": 12.389371,
          "end_time": "2022-03-01T05:06:17.126536",
          "exception": false,
          "start_time": "2022-03-01T05:06:04.737165",
          "status": "completed"
        },
        "tags": [],
        "id": "6440e8b9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 25920.724101,
      "end_time": "2022-03-01T05:06:33.282855",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-02-28T21:54:32.558754",
      "version": "2.3.3"
    },
    "colab": {
      "name": "bert-finetuned-triviaqa.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}