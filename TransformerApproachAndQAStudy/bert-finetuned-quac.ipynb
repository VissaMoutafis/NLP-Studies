{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1af15b7c",
      "metadata": {
        "papermill": {
          "duration": 0.016604,
          "end_time": "2022-03-02T13:29:58.439591",
          "exception": false,
          "start_time": "2022-03-02T13:29:58.422987",
          "status": "completed"
        },
        "tags": [],
        "id": "1af15b7c"
      },
      "source": [
        "# Finetune Bert on QuAC\n",
        "**Student Credentials:** sdi1800119, Vissarion Moutafis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bd1742b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-02T13:29:58.476447Z",
          "iopub.status.busy": "2022-03-02T13:29:58.474969Z",
          "iopub.status.idle": "2022-03-02T13:30:25.923173Z",
          "shell.execute_reply": "2022-03-02T13:30:25.923618Z",
          "shell.execute_reply.started": "2022-03-02T13:26:37.215309Z"
        },
        "papermill": {
          "duration": 27.46863,
          "end_time": "2022-03-02T13:30:25.923933",
          "exception": false,
          "start_time": "2022-03-02T13:29:58.455303",
          "status": "completed"
        },
        "tags": [],
        "id": "3bd1742b",
        "outputId": "f17d0e0f-ac5b-41ca-df95-40db2859926f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.15.0)\r\n",
            "Collecting datasets\r\n",
            "  Downloading datasets-1.18.3-py3-none-any.whl (311 kB)\r\n",
            "     |████████████████████████████████| 311 kB 924 kB/s            \r\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.10.1)\r\n",
            "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.47)\r\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.3)\r\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.4.2)\r\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.2.1)\r\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\r\n",
            "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.62.3)\r\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.20.3)\r\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\r\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.26.0)\r\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\r\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (6.0.1)\r\n",
            "Collecting xxhash\r\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\r\n",
            "     |████████████████████████████████| 212 kB 14.8 MB/s            \r\n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.12.2)\r\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2022.1.0)\r\n",
            "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.1)\r\n",
            "Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.4)\r\n",
            "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\r\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.0.1)\r\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.6)\r\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2021.10.8)\r\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.1)\r\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.7)\r\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.0.9)\r\n",
            "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\r\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\r\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.7.2)\r\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\r\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (21.2.0)\r\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.1)\r\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (5.2.0)\r\n",
            "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.6.0)\r\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\r\n",
            "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2021.3)\r\n",
            "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\r\n",
            "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.3)\r\n",
            "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.1.0)\r\n",
            "Installing collected packages: xxhash, datasets\r\n",
            "Successfully installed datasets-1.18.3 xxhash-3.0.0\r\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "The following NEW packages will be installed:\r\n",
            "  git-lfs\r\n",
            "0 upgraded, 1 newly installed, 0 to remove and 42 not upgraded.\r\n",
            "Need to get 3316 kB of archives.\r\n",
            "After this operation, 11.1 MB of additional disk space will be used.\r\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 git-lfs amd64 2.9.2-1 [3316 kB]\r\n",
            "Fetched 3316 kB in 2s (2139 kB/s)\r\n",
            "\n",
            "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package git-lfs.\r\n",
            "(Reading database ... 103272 files and directories currently installed.)\r\n",
            "Preparing to unpack .../git-lfs_2.9.2-1_amd64.deb ...\r\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 20%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Unpacking git-lfs (2.9.2-1) ...\r\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 40%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Setting up git-lfs (2.9.2-1) ...\r\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 60%]\u001b[49m\u001b[39m [##################################........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 80%]\u001b[49m\u001b[39m [##############################################............] \u001b8Processing triggers for man-db (2.9.1-1) ...\r\n",
            "\r\n",
            "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[JRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (4.62.3)\r\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn\n",
        "import re\n",
        "seaborn.set_style(\"ticks\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve, auc, classification_report\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchtext\n",
        "from torch.utils.data import SubsetRandomSampler\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "!pip install transformers datasets\n",
        "!apt install git-lfs\n",
        "import transformers\n",
        "import datasets\n",
        "from transformers import AutoModel, BertTokenizer, BertForSequenceClassification, AutoModelForSequenceClassification, AutoModelForQuestionAnswering\n",
        "from datasets import load_dataset, load_metric\n",
        "\n",
        "!pip install tqdm\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d924cc53",
      "metadata": {
        "papermill": {
          "duration": 0.036686,
          "end_time": "2022-03-02T13:30:25.997737",
          "exception": false,
          "start_time": "2022-03-02T13:30:25.961051",
          "status": "completed"
        },
        "tags": [],
        "id": "d924cc53"
      },
      "source": [
        "## Load the model and the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4fd8faf",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-02T13:30:26.073178Z",
          "iopub.status.busy": "2022-03-02T13:30:26.072447Z",
          "iopub.status.idle": "2022-03-02T13:30:26.074575Z",
          "shell.execute_reply": "2022-03-02T13:30:26.074984Z",
          "shell.execute_reply.started": "2022-03-02T13:27:04.256866Z"
        },
        "papermill": {
          "duration": 0.041614,
          "end_time": "2022-03-02T13:30:26.075123",
          "exception": false,
          "start_time": "2022-03-02T13:30:26.033509",
          "status": "completed"
        },
        "tags": [],
        "id": "e4fd8faf"
      },
      "outputs": [],
      "source": [
        "model_checkpoint = 'bert-base-uncased'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78e6bbb6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-02T13:30:26.145622Z",
          "iopub.status.busy": "2022-03-02T13:30:26.145120Z",
          "iopub.status.idle": "2022-03-02T13:30:36.462144Z",
          "shell.execute_reply": "2022-03-02T13:30:36.461312Z",
          "shell.execute_reply.started": "2022-03-02T13:27:04.264894Z"
        },
        "papermill": {
          "duration": 10.355462,
          "end_time": "2022-03-02T13:30:36.462277",
          "exception": false,
          "start_time": "2022-03-02T13:30:26.106815",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "42d395273e7a4f70a52dadc023a55555",
            "0da3f870b8ca4575814caae98deabb69"
          ]
        },
        "id": "78e6bbb6",
        "outputId": "e29e0179-58fa-4a31-a7f9-32c50bbb97e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset squad_like/default to /root/.cache/huggingface/datasets/squad_like/default-94886529e6fd8abb/0.0.0/c11bde73ef00f53b085b6a086d13514938f65b80af061fc874ce3e7514c24892...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42d395273e7a4f70a52dadc023a55555",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0da3f870b8ca4575814caae98deabb69",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset squad_like downloaded and prepared to /root/.cache/huggingface/datasets/squad_like/default-94886529e6fd8abb/0.0.0/c11bde73ef00f53b085b6a086d13514938f65b80af061fc874ce3e7514c24892. Subsequent calls will reuse this data.\n"
          ]
        }
      ],
      "source": [
        "train_dataset = load_dataset('../input/squadlikeloader/squad_like.py', data_files={'train':'../quactosquad/quac_train.json', 'validation':'../quactosquad/quac_val.json'}, split='train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "513f2ed9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-02T13:30:36.537172Z",
          "iopub.status.busy": "2022-03-02T13:30:36.536158Z",
          "iopub.status.idle": "2022-03-02T13:30:53.827633Z",
          "shell.execute_reply": "2022-03-02T13:30:53.828082Z",
          "shell.execute_reply.started": "2022-03-02T13:27:14.785555Z"
        },
        "papermill": {
          "duration": 17.33224,
          "end_time": "2022-03-02T13:30:53.828245",
          "exception": false,
          "start_time": "2022-03-02T13:30:36.496005",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "cdf7805fd318441991818373e1f02bc8",
            "034564a5a9cc490c9d378bd5d1affc54",
            "33c0d2cf58d94b198208dab5b255f510",
            "720e074c368d4c90904e3559d0a0e449",
            "007a47644680462a96e25599bb4fcc9f",
            "8833cd4c873f456db88415d8cc24f167",
            "9e9ecb4179be47ee9434d90a3fc288a5",
            "60dd1b4edae847fda71258375296f71f"
          ]
        },
        "id": "513f2ed9",
        "outputId": "dd9e4504-1634-41ba-b7b8-8f3bbee067e8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cdf7805fd318441991818373e1f02bc8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.87k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "034564a5a9cc490c9d378bd5d1affc54",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset squad_v2/squad_v2 (download: 44.34 MiB, generated: 122.41 MiB, post-processed: Unknown size, total: 166.75 MiB) to /root/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "33c0d2cf58d94b198208dab5b255f510",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "720e074c368d4c90904e3559d0a0e449",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/9.55M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "007a47644680462a96e25599bb4fcc9f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/801k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8833cd4c873f456db88415d8cc24f167",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e9ecb4179be47ee9434d90a3fc288a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60dd1b4edae847fda71258375296f71f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset squad_v2 downloaded and prepared to /root/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d. Subsequent calls will reuse this data.\n"
          ]
        }
      ],
      "source": [
        "test_dataset = load_dataset('squad_v2', split='validation')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess the dataset"
      ],
      "metadata": {
        "id": "KBKMQQBSFnWp"
      },
      "id": "KBKMQQBSFnWp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50bfe630",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-02T13:30:53.910122Z",
          "iopub.status.busy": "2022-03-02T13:30:53.909472Z",
          "iopub.status.idle": "2022-03-02T13:30:59.763459Z",
          "shell.execute_reply": "2022-03-02T13:30:59.762942Z",
          "shell.execute_reply.started": "2022-03-02T13:27:31.012627Z"
        },
        "papermill": {
          "duration": 5.896334,
          "end_time": "2022-03-02T13:30:59.763602",
          "exception": false,
          "start_time": "2022-03-02T13:30:53.867268",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "7aab568c1c524f3a922e16955337db94",
            "fa9e274a84434958b9edf89c6ad37d0a",
            "75a4d28e1d6a4ddfb9fc7b2373605c93",
            "da8e83bf1265434e9bebce90a835c31a"
          ]
        },
        "id": "50bfe630",
        "outputId": "14713b92-c4bc-42a4-de89-26b0df1896a5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7aab568c1c524f3a922e16955337db94",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa9e274a84434958b9edf89c6ad37d0a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75a4d28e1d6a4ddfb9fc7b2373605c93",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da8e83bf1265434e9bebce90a835c31a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "# initialize the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "MAX_LENGTH = 384\n",
        "DOC_STRIDE = 128 # multi-context overlapping range for large context'd instances \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34f8f978",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-02T13:30:59.858690Z",
          "iopub.status.busy": "2022-03-02T13:30:59.857563Z",
          "iopub.status.idle": "2022-03-02T13:30:59.859467Z",
          "shell.execute_reply": "2022-03-02T13:30:59.860145Z",
          "shell.execute_reply.started": "2022-03-02T13:27:38.696441Z"
        },
        "papermill": {
          "duration": 0.055924,
          "end_time": "2022-03-02T13:30:59.860288",
          "exception": false,
          "start_time": "2022-03-02T13:30:59.804364",
          "status": "completed"
        },
        "tags": [],
        "id": "34f8f978"
      },
      "outputs": [],
      "source": [
        "def preprocess_squad(examples):\n",
        "  # get the questions and the context\n",
        "  questions = [q.strip() for q in examples[\"question\"]]\n",
        "  context = examples[\"context\"]\n",
        "  # tokenize questions along with the context \n",
        "  inputs = tokenizer(\n",
        "        questions,\n",
        "        context,\n",
        "        max_length=MAX_LENGTH,\n",
        "        stride=DOC_STRIDE,\n",
        "        truncation=\"only_second\",\n",
        "        padding=\"max_length\",\n",
        "        return_offsets_mapping=True,\n",
        "        return_overflowing_tokens=True\n",
        "    )\n",
        "  offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "  sample_mapping = inputs.pop(\"overflow_to_sample_mapping\")\n",
        "  answers = examples[\"answers\"]\n",
        "  start_positions = []\n",
        "  end_positions = []\n",
        "  \n",
        "  for i, offset in enumerate(offset_mapping):\n",
        "    sample_index = sample_mapping[i]\n",
        "    answer = examples[\"answers\"][sample_index]\n",
        "    # if there is no answer default to [CLS]\n",
        "    if not answer[\"answer_start\"]:\n",
        "      start_positions.append(inputs['input_ids'][i].index(tokenizer.cls_token_id))\n",
        "      end_positions.append(inputs['input_ids'][i].index(tokenizer.cls_token_id))\n",
        "      continue \n",
        "    \n",
        "    # get answer start and end positions\n",
        "    start_char = answer[\"answer_start\"][0]\n",
        "    end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
        "    sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "    # Find the start and end of the context\n",
        "    idx = 0\n",
        "    while sequence_ids[idx] != 1:\n",
        "      idx += 1\n",
        "    context_start = idx\n",
        "    while sequence_ids[idx] == 1:\n",
        "      idx += 1\n",
        "    context_end = idx - 1\n",
        "\n",
        "    # If the answer is not fully inside the context, label it (0, 0)\n",
        "    if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
        "#       start_positions.append(inputs['input_ids'][i].index(tokenizer.cls_token_id))\n",
        "#       end_positions.append(inputs['input_ids'][i].index(tokenizer.cls_token_id))\n",
        "      start_positions.append(-1)\n",
        "      end_positions.append(-1)\n",
        "    else:\n",
        "      # Otherwise it's the start and end token positions\n",
        "      idx = context_start\n",
        "      while idx <= context_end and offset[idx][0] <= start_char:\n",
        "        idx += 1\n",
        "      start_positions.append(idx - 1)\n",
        "\n",
        "      idx = context_end\n",
        "      while idx >= context_start and offset[idx][1] >= end_char:\n",
        "        idx -= 1\n",
        "      end_positions.append(idx + 1)\n",
        "\n",
        "  inputs[\"start_positions\"] = start_positions\n",
        "  inputs[\"end_positions\"] = end_positions\n",
        "  return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afa2d55c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-02T13:30:59.959553Z",
          "iopub.status.busy": "2022-03-02T13:30:59.958528Z",
          "iopub.status.idle": "2022-03-02T13:32:11.935973Z",
          "shell.execute_reply": "2022-03-02T13:32:11.935184Z",
          "shell.execute_reply.started": "2022-03-02T13:27:38.711544Z"
        },
        "papermill": {
          "duration": 72.036242,
          "end_time": "2022-03-02T13:32:11.936108",
          "exception": false,
          "start_time": "2022-03-02T13:30:59.899866",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "317bb8f1b94e4a2e8e724905c9e4cdee",
            "26cc6f1735244f7fbc2b311c089b54b3"
          ]
        },
        "id": "afa2d55c",
        "outputId": "aa52e690-b6c2-4a1f-fbbf-8a03affd9734"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "317bb8f1b94e4a2e8e724905c9e4cdee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/84 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "26cc6f1735244f7fbc2b311c089b54b3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/12 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_dataset = train_dataset.map(preprocess_squad, batched=True, remove_columns=train_dataset.column_names)\n",
        "test_dataset = test_dataset.map(preprocess_squad, batched=True, remove_columns=test_dataset.column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d3055c1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-02T13:32:12.049363Z",
          "iopub.status.busy": "2022-03-02T13:32:12.048291Z",
          "iopub.status.idle": "2022-03-02T13:32:12.323324Z",
          "shell.execute_reply": "2022-03-02T13:32:12.323758Z",
          "shell.execute_reply.started": "2022-03-02T13:28:47.274898Z"
        },
        "papermill": {
          "duration": 0.344788,
          "end_time": "2022-03-02T13:32:12.323923",
          "exception": false,
          "start_time": "2022-03-02T13:32:11.979135",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "0931f0c755694045b55c5d4503d4fecf",
            "ee0881a3e3d34d70a236d2c3cd45f5d9"
          ]
        },
        "id": "2d3055c1",
        "outputId": "1e0320b4-0331-474f-d00b-c620bea5c928"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0931f0c755694045b55c5d4503d4fecf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/84 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee0881a3e3d34d70a236d2c3cd45f5d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/13 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def is_valid(s, e):\n",
        "    return s != -1 and e != -1\n",
        "\n",
        "train_dataset = train_dataset.filter(is_valid, input_columns=['start_positions', 'end_positions'])\n",
        "test_dataset = test_dataset.filter(is_valid, input_columns=['start_positions', 'end_positions'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e54ee882",
      "metadata": {
        "papermill": {
          "duration": 0.041956,
          "end_time": "2022-03-02T13:32:12.411268",
          "exception": false,
          "start_time": "2022-03-02T13:32:12.369312",
          "status": "completed"
        },
        "tags": [],
        "id": "e54ee882"
      },
      "source": [
        "## Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f2ef70d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-02T13:32:12.499269Z",
          "iopub.status.busy": "2022-03-02T13:32:12.498705Z",
          "iopub.status.idle": "2022-03-02T13:32:12.501755Z",
          "shell.execute_reply": "2022-03-02T13:32:12.501299Z",
          "shell.execute_reply.started": "2022-03-02T13:28:47.599489Z"
        },
        "papermill": {
          "duration": 0.049186,
          "end_time": "2022-03-02T13:32:12.501873",
          "exception": false,
          "start_time": "2022-03-02T13:32:12.452687",
          "status": "completed"
        },
        "tags": [],
        "id": "6f2ef70d"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=24, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=24, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13299a47",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-02T13:32:12.592004Z",
          "iopub.status.busy": "2022-03-02T13:32:12.591453Z",
          "iopub.status.idle": "2022-03-02T13:32:25.231506Z",
          "shell.execute_reply": "2022-03-02T13:32:25.232111Z",
          "shell.execute_reply.started": "2022-03-02T13:28:47.608100Z"
        },
        "papermill": {
          "duration": 12.68911,
          "end_time": "2022-03-02T13:32:25.232275",
          "exception": false,
          "start_time": "2022-03-02T13:32:12.543165",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "da8ac736ae0b40bc80bf44c3e5d7eb90"
          ]
        },
        "id": "13299a47",
        "outputId": "82afcdf1-2a4c-4fc9-fd06-d87981514e20"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da8ac736ae0b40bc80bf44c3e5d7eb90",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50794107",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-02T13:32:25.323961Z",
          "iopub.status.busy": "2022-03-02T13:32:25.323390Z",
          "iopub.status.idle": "2022-03-02T13:32:28.443422Z",
          "shell.execute_reply": "2022-03-02T13:32:28.444439Z",
          "shell.execute_reply.started": "2022-03-02T13:29:06.075049Z"
        },
        "papermill": {
          "duration": 3.169339,
          "end_time": "2022-03-02T13:32:28.444657",
          "exception": false,
          "start_time": "2022-03-02T13:32:25.275318",
          "status": "completed"
        },
        "tags": [],
        "id": "50794107",
        "outputId": "572d6532-f5ee-4473-8f46-c550ff257474"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertForQuestionAnswering(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "model.to(device)\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5de6ab3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-02T13:32:28.598503Z",
          "iopub.status.busy": "2022-03-02T13:32:28.597650Z",
          "iopub.status.idle": "2022-03-02T13:32:28.643095Z",
          "shell.execute_reply": "2022-03-02T13:32:28.644182Z",
          "shell.execute_reply.started": "2022-03-02T13:29:09.036750Z"
        },
        "papermill": {
          "duration": 0.128218,
          "end_time": "2022-03-02T13:32:28.644389",
          "exception": false,
          "start_time": "2022-03-02T13:32:28.516171",
          "status": "completed"
        },
        "tags": [],
        "id": "e5de6ab3"
      },
      "outputs": [],
      "source": [
        "def training_step(model, optimizer, epoch_i, train_loader, history=None):\n",
        "  torch.cuda.empty_cache()\n",
        "  # 1 step of backprop with train/test error estimation\n",
        "  total_loss = 0\n",
        "  acc = []\n",
        "  pbar = tqdm(train_loader)\n",
        "  for i,batch in enumerate(pbar):\n",
        "    torch.cuda.empty_cache()\n",
        "    # set the gradients to zero for new estimation\n",
        "    optimizer.zero_grad() \n",
        "    # forward pass\n",
        "    args = {\n",
        "        \"start_positions\" : torch.LongTensor(batch[\"start_positions\"]).to(device),\n",
        "        \"end_positions\" : torch.LongTensor(batch[\"end_positions\"]).to(device),\n",
        "        \"input_ids\" : torch.stack(batch[\"input_ids\"], axis=1).to(device),\n",
        "        \"attention_mask\" : torch.stack(batch[\"attention_mask\"], axis=1).to(device),\n",
        "    }\n",
        "    outputs = model(**args) \n",
        "    loss = outputs[0]\n",
        "    start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
        "    end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
        "    # compute loss \n",
        "    total_loss += loss.item()\n",
        "\n",
        "    # backpropagate error\n",
        "    loss.backward()\n",
        "    # apply gradient clipping adjust model's parameters\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
        "    optimizer.step()\n",
        "    \n",
        "    acc.append(((start_pred == args['start_positions']).sum()/len(start_pred)).item())\n",
        "    acc.append(((end_pred == args['end_positions']).sum()/len(end_pred)).item())\n",
        "    pbar.set_description('Epoch {}: train loss: {}, train accuracy: {}%'.format(epoch_i, total_loss/(i+1), sum(acc)/len(acc)), refresh=True)\n",
        "    \n",
        "  train_loss = total_loss/len(train_loader)\n",
        "    \n",
        "    # if the user provides with a history dict the training step will save the current epoch's train-test loss\n",
        "  if history is not None: \n",
        "    history['train'].append(train_loss)\n",
        "  \n",
        "  test_loss = 0\n",
        "  acc = []\n",
        "  pbar = tqdm(test_loader)\n",
        "  for i,batch in enumerate(pbar):\n",
        "    torch.cuda.empty_cache()\n",
        "    with torch.no_grad():\n",
        "      args = {\n",
        "          \"start_positions\" : torch.LongTensor(batch[\"start_positions\"]).to(device),\n",
        "          \"end_positions\" : torch.LongTensor(batch[\"end_positions\"]).to(device),\n",
        "          \"input_ids\" : torch.stack(batch[\"input_ids\"], axis=1).to(device),\n",
        "          \"attention_mask\" : torch.stack(batch[\"attention_mask\"], axis=1).to(device)\n",
        "        }\n",
        "      outputs = model(**args)\n",
        "      test_loss += outputs[0].item()\n",
        "      start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
        "      end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
        "      acc.append(((start_pred == args['start_positions']).sum()/len(start_pred)).item())\n",
        "      acc.append(((end_pred == args['end_positions']).sum()/len(end_pred)).item())\n",
        "      pbar.set_description('Epoch {}: test loss {}%, test accuracy {}%'.format(epoch_i, test_loss/(i+1), sum(acc)/len(acc)), refresh=True)\n",
        "        \n",
        "  if history is not None: \n",
        "    history['test'].append(test_loss/len(test_loader))\n",
        "    \n",
        "\n",
        "  \n",
        "  return train_loss, test_loss/len(test_loader), sum(acc)/len(acc)\n",
        "\n",
        "def train_model(history, model, train_loader, epochs, _lr):\n",
        "  # set to training mode\n",
        "  model.train()\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.AdamW(model.parameters(), lr = _lr)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    training_step(model, optimizer, epoch, train_loader, history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "684d8874",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-02T13:32:28.800615Z",
          "iopub.status.busy": "2022-03-02T13:32:28.799815Z",
          "iopub.status.idle": "2022-03-02T14:57:30.118775Z",
          "shell.execute_reply": "2022-03-02T14:57:30.119321Z",
          "shell.execute_reply.started": "2022-03-02T13:29:09.072198Z"
        },
        "papermill": {
          "duration": 5101.40365,
          "end_time": "2022-03-02T14:57:30.119492",
          "exception": false,
          "start_time": "2022-03-02T13:32:28.715842",
          "status": "completed"
        },
        "tags": [],
        "id": "684d8874",
        "outputId": "a88d162d-5a53-4483-9fdc-6fcab10a76f0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 0: train loss: 3.3921460354744397, train accuracy: 0.3606420633146933%: 100%|██████████| 1747/1747 [39:19<00:00,  1.35s/it]\n",
            "Epoch 0: test loss 3.4228402898606074%, test accuracy 0.4569223232240791%: 100%|██████████| 502/502 [03:04<00:00,  2.73it/s]\n",
            "Epoch 1: train loss: 3.1554847793983063, train accuracy: 0.37926923389678247%: 100%|██████████| 1747/1747 [39:32<00:00,  1.36s/it]\n",
            "Epoch 1: test loss 3.7013701684921387%, test accuracy 0.36824923567102846%: 100%|██████████| 502/502 [03:05<00:00,  2.71it/s]\n"
          ]
        }
      ],
      "source": [
        "history = {'train':[], 'test':[]}\n",
        "train_model(history, model, train_loader, 2,  3e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload the model"
      ],
      "metadata": {
        "id": "iaFErNTwFxQV"
      },
      "id": "iaFErNTwFxQV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1361bdff",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-02T14:57:36.016751Z",
          "iopub.status.busy": "2022-03-02T14:57:36.016159Z",
          "iopub.status.idle": "2022-03-02T14:59:00.401860Z",
          "shell.execute_reply": "2022-03-02T14:59:00.401351Z",
          "shell.execute_reply.started": "2022-03-02T13:29:28.533667Z"
        },
        "papermill": {
          "duration": 87.365182,
          "end_time": "2022-03-02T14:59:00.402001",
          "exception": false,
          "start_time": "2022-03-02T14:57:33.036819",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "4d220ba0f39042e3a081c5ae3ec54732"
          ]
        },
        "id": "1361bdff",
        "outputId": "9c47e162-3f46-4523-9bf5-930d275b91f9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/huggingface_hub/hf_api.py:726: FutureWarning: `create_repo` now takes `token` as an optional positional argument. Be sure to adapt your code!\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cloning https://huggingface.co/vissa/bert-finetuned-quac into local empty directory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d220ba0f39042e3a081c5ae3ec54732",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload file pytorch_model.bin:   0%|          | 32.0k/415M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "To https://huggingface.co/vissa/bert-finetuned-quac\n",
            "   b57f495..b4c1a7d  main -> main\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'https://huggingface.co/vissa/bert-finetuned-quac/commit/b4c1a7dc870bdbdfe73a95c5c30c2af907fd7f22'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.push_to_hub('vissa/bert-finetuned-quac', use_auth_token='YOUR_WRT_TOKEN_HERE')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e176766",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-02T14:59:06.198935Z",
          "iopub.status.busy": "2022-03-02T14:59:06.198050Z",
          "iopub.status.idle": "2022-03-02T14:59:06.998858Z",
          "shell.execute_reply": "2022-03-02T14:59:06.999549Z",
          "shell.execute_reply.started": "2022-03-02T13:29:28.535588Z"
        },
        "papermill": {
          "duration": 3.764302,
          "end_time": "2022-03-02T14:59:06.999778",
          "exception": false,
          "start_time": "2022-03-02T14:59:03.235476",
          "status": "completed"
        },
        "tags": [],
        "id": "0e176766"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained('./' , private=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33b47e41",
      "metadata": {
        "papermill": {
          "duration": 2.93453,
          "end_time": "2022-03-02T14:59:13.022559",
          "exception": false,
          "start_time": "2022-03-02T14:59:10.088029",
          "status": "completed"
        },
        "tags": [],
        "id": "33b47e41"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 5368.792578,
      "end_time": "2022-03-02T14:59:19.334041",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-03-02T13:29:50.541463",
      "version": "2.3.3"
    },
    "colab": {
      "name": "bert-finetuned-quac.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}